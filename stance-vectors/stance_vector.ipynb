{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "import setup_modules\n",
    "from lib.preprocessing import setup_enhance, ngram_enhance, process, load_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../working-csvs/fomc-sents-w-sentiment.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams, trigrams = setup_enhance('../ngrams/bigrams', '../ngrams/trigrams')\n",
    "df['enhanced'] = df['content'].map(lambda x : ngram_enhance(x, bigrams, trigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = load_stopwords('../stopwords/stopwords.txt')\n",
    "stemmer = PorterStemmer()\n",
    "df['tokens'] = df['enhanced'].map(lambda x : process(x, stemmer=stemmer, stopwords=stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model = LdaModel.load('../models/02-29/02-29lda')\n",
    "model_dict = Dictionary.load('../models/02-29/02-29dict')\n",
    "# topic_model = LdaModel.load('../models/12-10lda')\n",
    "# model_dict = Dictionary.load('../models/12-10dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tprob_vect'] = df['tokens'].map(lambda x : topic_model[model_dict.doc2bow(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topk_topics(topic_vec, k=3):\n",
    "    probs = [item[1] for item in topic_vec]\n",
    "    probs.sort(reverse=True)\n",
    "    threshold = probs[k - 1]\n",
    "    topk = [item for item in topic_vec if item[1] >= max(threshold, 0.03)]\n",
    "    rounded = [(topic, round(prob,4)) for topic, prob in topk]\n",
    "    return rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['topk'] = df['tprob_vect'].map(lambda x : topk_topics(x, k=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Economic activity in the Eighth District has been improving at a moderate pace during the intermeeting period.\n",
      "[(21, 0.0483)]\n",
      "For example, I've maintained my forecast for 2013 and 2014 at about 3 percent, and I believe that looking at the horizon of 18 months to two years is a better horizon for which policy ought to be judged, and ought to be the relevant metric we should look at.\n",
      "[(13, 0.037), (44, 0.0344)]\n",
      "You will recall that in 1992 the Swedes tried to curb a run on their exchange rate by raising their overnight interest rate to 500 percent.\n",
      "[(8, 0.0357), (37, 0.0402), (38, 0.0387)]\n",
      "I take more signal about the underlying strength of the economy from the improvement in labor market conditions, which has exceeded the expectations of many economists.\n",
      "[(36, 0.0377)]\n",
      "Turning to the inflation outlook for the immediate future, I think the most likely outcome is for stable or even slightly lower core inflation this year.\n",
      "[(34, 0.0502), (39, 0.031)]\n",
      "For now, I lean toward the view that low inflation is transitory, with the signal from recent readings blurred by declines in a few components.\n",
      "[(30, 0.0308), (43, 0.0316)]\n",
      "I think we do need to be sensitive to the possibility of overshooting, and here I would endorse President Hoenig's comments on that.\n",
      "[(37, 0.0338)]\n",
      "One is the valuation risk:  All of a sudden people realized that they didn't know as much about what kind of assets were in portfolios and how complicated the structures were in terms of those assets.\n",
      "[(10, 0.0325), (12, 0.0324), (22, 0.0462)]\n",
      "European sovereign banking problems have created significant uncertainties, and these problems could be transmitted to the United States via money market funds, domestic banks, or changes in risk aversion.\n",
      "[(11, 0.0353), (18, 0.051), (35, 0.056)]\n",
      "So, for now, this is really a bubble theory of inflation, as I think about it.\n",
      "[(6, 0.0313), (19, 0.032)]\n",
      "So far, the charge-off rates in 2009 on nonfarm, nonresidential mortgages ran about 1 percent, which is actually just half of the 2 percent charge- off rate on residential mortgages or C&I loans and a fraction of the more than 5 percent charge- off rate on construction loans.\n",
      "[(22, 0.1676)]\n",
      "I wouldn't propose that as long as you are the Chair, but I suspect we may at some point want to spend more time together as we go forward.\n",
      "[(8, 0.0309)]\n"
     ]
    }
   ],
   "source": [
    "for i, row in df.sample(20)[['content', 'topk']].iterrows():\n",
    "    if len(row['topk']) > 0:\n",
    "        print(row['content'])\n",
    "        print(row['topk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 45\n",
    "\n",
    "def partial_stance_vect(topics, sent_label):\n",
    "    # maybe normalize\n",
    "    total = sum([topic[1] for topic in topics])\n",
    "    svect = [0] * k\n",
    "    for topic, weight in topics:\n",
    "        svect[topic] = float(sent_label) * float(weight) / total\n",
    "    \n",
    "    return np.array(svect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sent_prob = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = df[(df['topk'].map(len) > 0) & (df['sent_prob'] > 0.5) & (df['sent'] != 0)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['svect'] = dff.apply(lambda x : partial_stance_vect(x['topk'], x['sent']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lname</th>\n",
       "      <th>date</th>\n",
       "      <th>section</th>\n",
       "      <th>content</th>\n",
       "      <th>sent_prob</th>\n",
       "      <th>sent</th>\n",
       "      <th>enhanced</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tprob_vect</th>\n",
       "      <th>topk</th>\n",
       "      <th>svect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bernanke</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>1</td>\n",
       "      <td>As we search for the signal of an incipient re...</td>\n",
       "      <td>0.819317</td>\n",
       "      <td>-1</td>\n",
       "      <td>As we search for the signal of an incipient re...</td>\n",
       "      <td>[search, signal, incipi, recoveri, heavi, nois...</td>\n",
       "      <td>[(0, 0.020856535), (1, 0.021945685), (2, 0.020...</td>\n",
       "      <td>[(36, 0.0359)]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bernanke</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>1</td>\n",
       "      <td>The direct effects of the stock market are bei...</td>\n",
       "      <td>0.654100</td>\n",
       "      <td>-1</td>\n",
       "      <td>The direct effects of the stock market are bei...</td>\n",
       "      <td>[direct, effect, stock, market, partli, offset...</td>\n",
       "      <td>[(0, 0.023129959), (1, 0.02173418), (2, 0.0206...</td>\n",
       "      <td>[(34, 0.0308)]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bernanke</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>1</td>\n",
       "      <td>Second, regarding the other source of noise, t...</td>\n",
       "      <td>0.840512</td>\n",
       "      <td>-1</td>\n",
       "      <td>Second, regarding the other source of noise, t...</td>\n",
       "      <td>[sourc, nois, data, revis, longer, blame, shal...</td>\n",
       "      <td>[(0, 0.019851433), (1, 0.020303724), (2, 0.020...</td>\n",
       "      <td>[(13, 0.0327), (18, 0.0312)]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bernanke</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>1</td>\n",
       "      <td>In particular, the revision has largely left i...</td>\n",
       "      <td>0.827082</td>\n",
       "      <td>1</td>\n",
       "      <td>In particular, the revision has largely left i...</td>\n",
       "      <td>[revis, larg, left, intact, growth, product, s...</td>\n",
       "      <td>[(0, 0.02214655), (1, 0.030765276), (2, 0.0211...</td>\n",
       "      <td>[(1, 0.0308), (37, 0.0487), (39, 0.0395)]</td>\n",
       "      <td>[0.0, 0.2588235220458918, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bernanke</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>1</td>\n",
       "      <td>I note the comments that Governor Kohn made ab...</td>\n",
       "      <td>0.803425</td>\n",
       "      <td>-1</td>\n",
       "      <td>I note the comments that Governor Kohn made ab...</td>\n",
       "      <td>[note, comment, governor, kohn, made, financi,...</td>\n",
       "      <td>[(0, 0.019764122), (1, 0.020307602), (2, 0.020...</td>\n",
       "      <td>[(27, 0.0347), (35, 0.0491)]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6701</th>\n",
       "      <td>yellen</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>2</td>\n",
       "      <td>I have thoroughly enjoyed interacting with all...</td>\n",
       "      <td>0.763187</td>\n",
       "      <td>1</td>\n",
       "      <td>I have thoroughly enjoyed interacting with all...</td>\n",
       "      <td>[enjoy, interact, terrif, staff, incred, honor...</td>\n",
       "      <td>[(0, 0.019811908), (1, 0.022919705), (2, 0.038...</td>\n",
       "      <td>[(2, 0.039)]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6701</th>\n",
       "      <td>yellen</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>2</td>\n",
       "      <td>I have heard considerable support during the g...</td>\n",
       "      <td>0.862407</td>\n",
       "      <td>1</td>\n",
       "      <td>I have heard considerable support during the g...</td>\n",
       "      <td>[heard, consider, support, round, alt, b, writ...</td>\n",
       "      <td>[(0, 0.019650389), (1, 0.019794215), (2, 0.020...</td>\n",
       "      <td>[(4, 0.056)]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6701</th>\n",
       "      <td>yellen</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>2</td>\n",
       "      <td>I suppose, although nothing obviously is set i...</td>\n",
       "      <td>0.907364</td>\n",
       "      <td>1</td>\n",
       "      <td>I suppose, although nothing obviously is set i...</td>\n",
       "      <td>[suppos, set, stone, s, a, pretti, strong, inc...</td>\n",
       "      <td>[(0, 0.020269258), (1, 0.019947713), (2, 0.021...</td>\n",
       "      <td>[(12, 0.0306), (37, 0.0392)]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6701</th>\n",
       "      <td>yellen</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>2</td>\n",
       "      <td>The minutes, if you have listened to the discu...</td>\n",
       "      <td>0.602243</td>\n",
       "      <td>1</td>\n",
       "      <td>The minutes, if you have listened to the discu...</td>\n",
       "      <td>[minut, listen, discuss, tabl, signal, greater...</td>\n",
       "      <td>[(0, 0.019247059), (1, 0.018644728), (2, 0.033...</td>\n",
       "      <td>[(2, 0.0335), (39, 0.0591)]</td>\n",
       "      <td>[0.0, 0.0, 0.36177107061022307, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6701</th>\n",
       "      <td>yellen</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>2</td>\n",
       "      <td>I mean, there was a reason to include it in bo...</td>\n",
       "      <td>0.620773</td>\n",
       "      <td>1</td>\n",
       "      <td>I mean, there was a reason to include it in bo...</td>\n",
       "      <td>[a, reason, includ, place, case, a, big, upwar...</td>\n",
       "      <td>[(0, 0.021386785), (1, 0.020505385), (2, 0.021...</td>\n",
       "      <td>[(19, 0.0309)]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79938 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         lname        date  section  \\\n",
       "0     bernanke  2002-08-13        1   \n",
       "0     bernanke  2002-08-13        1   \n",
       "0     bernanke  2002-08-13        1   \n",
       "0     bernanke  2002-08-13        1   \n",
       "0     bernanke  2002-08-13        1   \n",
       "...        ...         ...      ...   \n",
       "6701    yellen  2018-01-31        2   \n",
       "6701    yellen  2018-01-31        2   \n",
       "6701    yellen  2018-01-31        2   \n",
       "6701    yellen  2018-01-31        2   \n",
       "6701    yellen  2018-01-31        2   \n",
       "\n",
       "                                                content  sent_prob  sent  \\\n",
       "0     As we search for the signal of an incipient re...   0.819317    -1   \n",
       "0     The direct effects of the stock market are bei...   0.654100    -1   \n",
       "0     Second, regarding the other source of noise, t...   0.840512    -1   \n",
       "0     In particular, the revision has largely left i...   0.827082     1   \n",
       "0     I note the comments that Governor Kohn made ab...   0.803425    -1   \n",
       "...                                                 ...        ...   ...   \n",
       "6701  I have thoroughly enjoyed interacting with all...   0.763187     1   \n",
       "6701  I have heard considerable support during the g...   0.862407     1   \n",
       "6701  I suppose, although nothing obviously is set i...   0.907364     1   \n",
       "6701  The minutes, if you have listened to the discu...   0.602243     1   \n",
       "6701  I mean, there was a reason to include it in bo...   0.620773     1   \n",
       "\n",
       "                                               enhanced  \\\n",
       "0     As we search for the signal of an incipient re...   \n",
       "0     The direct effects of the stock market are bei...   \n",
       "0     Second, regarding the other source of noise, t...   \n",
       "0     In particular, the revision has largely left i...   \n",
       "0     I note the comments that Governor Kohn made ab...   \n",
       "...                                                 ...   \n",
       "6701  I have thoroughly enjoyed interacting with all...   \n",
       "6701  I have heard considerable support during the g...   \n",
       "6701  I suppose, although nothing obviously is set i...   \n",
       "6701  The minutes, if you have listened to the discu...   \n",
       "6701  I mean, there was a reason to include it in bo...   \n",
       "\n",
       "                                                 tokens  \\\n",
       "0     [search, signal, incipi, recoveri, heavi, nois...   \n",
       "0     [direct, effect, stock, market, partli, offset...   \n",
       "0     [sourc, nois, data, revis, longer, blame, shal...   \n",
       "0     [revis, larg, left, intact, growth, product, s...   \n",
       "0     [note, comment, governor, kohn, made, financi,...   \n",
       "...                                                 ...   \n",
       "6701  [enjoy, interact, terrif, staff, incred, honor...   \n",
       "6701  [heard, consider, support, round, alt, b, writ...   \n",
       "6701  [suppos, set, stone, s, a, pretti, strong, inc...   \n",
       "6701  [minut, listen, discuss, tabl, signal, greater...   \n",
       "6701  [a, reason, includ, place, case, a, big, upwar...   \n",
       "\n",
       "                                             tprob_vect  \\\n",
       "0     [(0, 0.020856535), (1, 0.021945685), (2, 0.020...   \n",
       "0     [(0, 0.023129959), (1, 0.02173418), (2, 0.0206...   \n",
       "0     [(0, 0.019851433), (1, 0.020303724), (2, 0.020...   \n",
       "0     [(0, 0.02214655), (1, 0.030765276), (2, 0.0211...   \n",
       "0     [(0, 0.019764122), (1, 0.020307602), (2, 0.020...   \n",
       "...                                                 ...   \n",
       "6701  [(0, 0.019811908), (1, 0.022919705), (2, 0.038...   \n",
       "6701  [(0, 0.019650389), (1, 0.019794215), (2, 0.020...   \n",
       "6701  [(0, 0.020269258), (1, 0.019947713), (2, 0.021...   \n",
       "6701  [(0, 0.019247059), (1, 0.018644728), (2, 0.033...   \n",
       "6701  [(0, 0.021386785), (1, 0.020505385), (2, 0.021...   \n",
       "\n",
       "                                           topk  \\\n",
       "0                                [(36, 0.0359)]   \n",
       "0                                [(34, 0.0308)]   \n",
       "0                  [(13, 0.0327), (18, 0.0312)]   \n",
       "0     [(1, 0.0308), (37, 0.0487), (39, 0.0395)]   \n",
       "0                  [(27, 0.0347), (35, 0.0491)]   \n",
       "...                                         ...   \n",
       "6701                               [(2, 0.039)]   \n",
       "6701                               [(4, 0.056)]   \n",
       "6701               [(12, 0.0306), (37, 0.0392)]   \n",
       "6701                [(2, 0.0335), (39, 0.0591)]   \n",
       "6701                             [(19, 0.0309)]   \n",
       "\n",
       "                                                  svect  \n",
       "0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "0     [0.0, 0.2588235220458918, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "...                                                 ...  \n",
       "6701  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "6701  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "6701  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "6701  [0.0, 0.0, 0.36177107061022307, 0.0, 0.0, 0.0,...  \n",
       "6701  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "\n",
       "[79938 rows x 11 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fomc = pd.read_csv('../working-csvs/fomc.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fomc['date_pd'] = pd.to_datetime(fomc['date'])\n",
    "fomc['year'] = fomc['date_pd'].dt.year\n",
    "fomc['month'] = fomc['date_pd'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['date_pd'] = pd.to_datetime(dff['date'].map(str))\n",
    "dff['year'] = dff['date_pd'].dt.year\n",
    "dff['month'] = dff['date_pd'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdff = dff.merge(fomc, how='left', left_on=['year', 'month', 'lname'], right_on=['year', 'month', 'member'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lname</th>\n",
       "      <th>date_x</th>\n",
       "      <th>section</th>\n",
       "      <th>content</th>\n",
       "      <th>sent_prob</th>\n",
       "      <th>sent</th>\n",
       "      <th>enhanced</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tprob_vect</th>\n",
       "      <th>topk</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>date_y</th>\n",
       "      <th>member</th>\n",
       "      <th>voter</th>\n",
       "      <th>region</th>\n",
       "      <th>female</th>\n",
       "      <th>chair</th>\n",
       "      <th>exp</th>\n",
       "      <th>date_pd_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bernanke</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>1</td>\n",
       "      <td>As we search for the signal of an incipient re...</td>\n",
       "      <td>0.819317</td>\n",
       "      <td>-1</td>\n",
       "      <td>As we search for the signal of an incipient re...</td>\n",
       "      <td>[search, signal, incipi, recoveri, heavi, nois...</td>\n",
       "      <td>[(0, 0.020856535), (1, 0.021945685), (2, 0.020...</td>\n",
       "      <td>[(36, 0.0359)]</td>\n",
       "      <td>...</td>\n",
       "      <td>2002</td>\n",
       "      <td>8</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>bernanke</td>\n",
       "      <td>1</td>\n",
       "      <td>governor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Greenspan</td>\n",
       "      <td>0.021918</td>\n",
       "      <td>2002-08-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bernanke</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>1</td>\n",
       "      <td>The direct effects of the stock market are bei...</td>\n",
       "      <td>0.654100</td>\n",
       "      <td>-1</td>\n",
       "      <td>The direct effects of the stock market are bei...</td>\n",
       "      <td>[direct, effect, stock, market, partli, offset...</td>\n",
       "      <td>[(0, 0.023129959), (1, 0.02173418), (2, 0.0206...</td>\n",
       "      <td>[(34, 0.0308)]</td>\n",
       "      <td>...</td>\n",
       "      <td>2002</td>\n",
       "      <td>8</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>bernanke</td>\n",
       "      <td>1</td>\n",
       "      <td>governor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Greenspan</td>\n",
       "      <td>0.021918</td>\n",
       "      <td>2002-08-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bernanke</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>1</td>\n",
       "      <td>Second, regarding the other source of noise, t...</td>\n",
       "      <td>0.840512</td>\n",
       "      <td>-1</td>\n",
       "      <td>Second, regarding the other source of noise, t...</td>\n",
       "      <td>[sourc, nois, data, revis, longer, blame, shal...</td>\n",
       "      <td>[(0, 0.019851433), (1, 0.020303724), (2, 0.020...</td>\n",
       "      <td>[(13, 0.0327), (18, 0.0312)]</td>\n",
       "      <td>...</td>\n",
       "      <td>2002</td>\n",
       "      <td>8</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>bernanke</td>\n",
       "      <td>1</td>\n",
       "      <td>governor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Greenspan</td>\n",
       "      <td>0.021918</td>\n",
       "      <td>2002-08-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bernanke</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>1</td>\n",
       "      <td>In particular, the revision has largely left i...</td>\n",
       "      <td>0.827082</td>\n",
       "      <td>1</td>\n",
       "      <td>In particular, the revision has largely left i...</td>\n",
       "      <td>[revis, larg, left, intact, growth, product, s...</td>\n",
       "      <td>[(0, 0.02214655), (1, 0.030765276), (2, 0.0211...</td>\n",
       "      <td>[(1, 0.0308), (37, 0.0487), (39, 0.0395)]</td>\n",
       "      <td>...</td>\n",
       "      <td>2002</td>\n",
       "      <td>8</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>bernanke</td>\n",
       "      <td>1</td>\n",
       "      <td>governor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Greenspan</td>\n",
       "      <td>0.021918</td>\n",
       "      <td>2002-08-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bernanke</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>1</td>\n",
       "      <td>I note the comments that Governor Kohn made ab...</td>\n",
       "      <td>0.803425</td>\n",
       "      <td>-1</td>\n",
       "      <td>I note the comments that Governor Kohn made ab...</td>\n",
       "      <td>[note, comment, governor, kohn, made, financi,...</td>\n",
       "      <td>[(0, 0.019764122), (1, 0.020307602), (2, 0.020...</td>\n",
       "      <td>[(27, 0.0347), (35, 0.0491)]</td>\n",
       "      <td>...</td>\n",
       "      <td>2002</td>\n",
       "      <td>8</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>bernanke</td>\n",
       "      <td>1</td>\n",
       "      <td>governor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Greenspan</td>\n",
       "      <td>0.021918</td>\n",
       "      <td>2002-08-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79933</th>\n",
       "      <td>yellen</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>2</td>\n",
       "      <td>I have thoroughly enjoyed interacting with all...</td>\n",
       "      <td>0.763187</td>\n",
       "      <td>1</td>\n",
       "      <td>I have thoroughly enjoyed interacting with all...</td>\n",
       "      <td>[enjoy, interact, terrif, staff, incred, honor...</td>\n",
       "      <td>[(0, 0.019811908), (1, 0.022919705), (2, 0.038...</td>\n",
       "      <td>[(2, 0.039)]</td>\n",
       "      <td>...</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>yellen</td>\n",
       "      <td>1</td>\n",
       "      <td>governor</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yellen</td>\n",
       "      <td>16.161644</td>\n",
       "      <td>2018-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79934</th>\n",
       "      <td>yellen</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>2</td>\n",
       "      <td>I have heard considerable support during the g...</td>\n",
       "      <td>0.862407</td>\n",
       "      <td>1</td>\n",
       "      <td>I have heard considerable support during the g...</td>\n",
       "      <td>[heard, consider, support, round, alt, b, writ...</td>\n",
       "      <td>[(0, 0.019650389), (1, 0.019794215), (2, 0.020...</td>\n",
       "      <td>[(4, 0.056)]</td>\n",
       "      <td>...</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>yellen</td>\n",
       "      <td>1</td>\n",
       "      <td>governor</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yellen</td>\n",
       "      <td>16.161644</td>\n",
       "      <td>2018-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79935</th>\n",
       "      <td>yellen</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>2</td>\n",
       "      <td>I suppose, although nothing obviously is set i...</td>\n",
       "      <td>0.907364</td>\n",
       "      <td>1</td>\n",
       "      <td>I suppose, although nothing obviously is set i...</td>\n",
       "      <td>[suppos, set, stone, s, a, pretti, strong, inc...</td>\n",
       "      <td>[(0, 0.020269258), (1, 0.019947713), (2, 0.021...</td>\n",
       "      <td>[(12, 0.0306), (37, 0.0392)]</td>\n",
       "      <td>...</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>yellen</td>\n",
       "      <td>1</td>\n",
       "      <td>governor</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yellen</td>\n",
       "      <td>16.161644</td>\n",
       "      <td>2018-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79936</th>\n",
       "      <td>yellen</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>2</td>\n",
       "      <td>The minutes, if you have listened to the discu...</td>\n",
       "      <td>0.602243</td>\n",
       "      <td>1</td>\n",
       "      <td>The minutes, if you have listened to the discu...</td>\n",
       "      <td>[minut, listen, discuss, tabl, signal, greater...</td>\n",
       "      <td>[(0, 0.019247059), (1, 0.018644728), (2, 0.033...</td>\n",
       "      <td>[(2, 0.0335), (39, 0.0591)]</td>\n",
       "      <td>...</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>yellen</td>\n",
       "      <td>1</td>\n",
       "      <td>governor</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yellen</td>\n",
       "      <td>16.161644</td>\n",
       "      <td>2018-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79937</th>\n",
       "      <td>yellen</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>2</td>\n",
       "      <td>I mean, there was a reason to include it in bo...</td>\n",
       "      <td>0.620773</td>\n",
       "      <td>1</td>\n",
       "      <td>I mean, there was a reason to include it in bo...</td>\n",
       "      <td>[a, reason, includ, place, case, a, big, upwar...</td>\n",
       "      <td>[(0, 0.021386785), (1, 0.020505385), (2, 0.021...</td>\n",
       "      <td>[(19, 0.0309)]</td>\n",
       "      <td>...</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>yellen</td>\n",
       "      <td>1</td>\n",
       "      <td>governor</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yellen</td>\n",
       "      <td>16.161644</td>\n",
       "      <td>2018-01-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79938 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          lname      date_x  section  \\\n",
       "0      bernanke  2002-08-13        1   \n",
       "1      bernanke  2002-08-13        1   \n",
       "2      bernanke  2002-08-13        1   \n",
       "3      bernanke  2002-08-13        1   \n",
       "4      bernanke  2002-08-13        1   \n",
       "...         ...         ...      ...   \n",
       "79933    yellen  2018-01-31        2   \n",
       "79934    yellen  2018-01-31        2   \n",
       "79935    yellen  2018-01-31        2   \n",
       "79936    yellen  2018-01-31        2   \n",
       "79937    yellen  2018-01-31        2   \n",
       "\n",
       "                                                 content  sent_prob  sent  \\\n",
       "0      As we search for the signal of an incipient re...   0.819317    -1   \n",
       "1      The direct effects of the stock market are bei...   0.654100    -1   \n",
       "2      Second, regarding the other source of noise, t...   0.840512    -1   \n",
       "3      In particular, the revision has largely left i...   0.827082     1   \n",
       "4      I note the comments that Governor Kohn made ab...   0.803425    -1   \n",
       "...                                                  ...        ...   ...   \n",
       "79933  I have thoroughly enjoyed interacting with all...   0.763187     1   \n",
       "79934  I have heard considerable support during the g...   0.862407     1   \n",
       "79935  I suppose, although nothing obviously is set i...   0.907364     1   \n",
       "79936  The minutes, if you have listened to the discu...   0.602243     1   \n",
       "79937  I mean, there was a reason to include it in bo...   0.620773     1   \n",
       "\n",
       "                                                enhanced  \\\n",
       "0      As we search for the signal of an incipient re...   \n",
       "1      The direct effects of the stock market are bei...   \n",
       "2      Second, regarding the other source of noise, t...   \n",
       "3      In particular, the revision has largely left i...   \n",
       "4      I note the comments that Governor Kohn made ab...   \n",
       "...                                                  ...   \n",
       "79933  I have thoroughly enjoyed interacting with all...   \n",
       "79934  I have heard considerable support during the g...   \n",
       "79935  I suppose, although nothing obviously is set i...   \n",
       "79936  The minutes, if you have listened to the discu...   \n",
       "79937  I mean, there was a reason to include it in bo...   \n",
       "\n",
       "                                                  tokens  \\\n",
       "0      [search, signal, incipi, recoveri, heavi, nois...   \n",
       "1      [direct, effect, stock, market, partli, offset...   \n",
       "2      [sourc, nois, data, revis, longer, blame, shal...   \n",
       "3      [revis, larg, left, intact, growth, product, s...   \n",
       "4      [note, comment, governor, kohn, made, financi,...   \n",
       "...                                                  ...   \n",
       "79933  [enjoy, interact, terrif, staff, incred, honor...   \n",
       "79934  [heard, consider, support, round, alt, b, writ...   \n",
       "79935  [suppos, set, stone, s, a, pretti, strong, inc...   \n",
       "79936  [minut, listen, discuss, tabl, signal, greater...   \n",
       "79937  [a, reason, includ, place, case, a, big, upwar...   \n",
       "\n",
       "                                              tprob_vect  \\\n",
       "0      [(0, 0.020856535), (1, 0.021945685), (2, 0.020...   \n",
       "1      [(0, 0.023129959), (1, 0.02173418), (2, 0.0206...   \n",
       "2      [(0, 0.019851433), (1, 0.020303724), (2, 0.020...   \n",
       "3      [(0, 0.02214655), (1, 0.030765276), (2, 0.0211...   \n",
       "4      [(0, 0.019764122), (1, 0.020307602), (2, 0.020...   \n",
       "...                                                  ...   \n",
       "79933  [(0, 0.019811908), (1, 0.022919705), (2, 0.038...   \n",
       "79934  [(0, 0.019650389), (1, 0.019794215), (2, 0.020...   \n",
       "79935  [(0, 0.020269258), (1, 0.019947713), (2, 0.021...   \n",
       "79936  [(0, 0.019247059), (1, 0.018644728), (2, 0.033...   \n",
       "79937  [(0, 0.021386785), (1, 0.020505385), (2, 0.021...   \n",
       "\n",
       "                                            topk  ...  year month      date_y  \\\n",
       "0                                 [(36, 0.0359)]  ...  2002     8  2002-08-13   \n",
       "1                                 [(34, 0.0308)]  ...  2002     8  2002-08-13   \n",
       "2                   [(13, 0.0327), (18, 0.0312)]  ...  2002     8  2002-08-13   \n",
       "3      [(1, 0.0308), (37, 0.0487), (39, 0.0395)]  ...  2002     8  2002-08-13   \n",
       "4                   [(27, 0.0347), (35, 0.0491)]  ...  2002     8  2002-08-13   \n",
       "...                                          ...  ...   ...   ...         ...   \n",
       "79933                               [(2, 0.039)]  ...  2018     1  2018-01-31   \n",
       "79934                               [(4, 0.056)]  ...  2018     1  2018-01-31   \n",
       "79935               [(12, 0.0306), (37, 0.0392)]  ...  2018     1  2018-01-31   \n",
       "79936                [(2, 0.0335), (39, 0.0591)]  ...  2018     1  2018-01-31   \n",
       "79937                             [(19, 0.0309)]  ...  2018     1  2018-01-31   \n",
       "\n",
       "         member voter    region  female      chair        exp  date_pd_y  \n",
       "0      bernanke     1  governor     0.0  Greenspan   0.021918 2002-08-13  \n",
       "1      bernanke     1  governor     0.0  Greenspan   0.021918 2002-08-13  \n",
       "2      bernanke     1  governor     0.0  Greenspan   0.021918 2002-08-13  \n",
       "3      bernanke     1  governor     0.0  Greenspan   0.021918 2002-08-13  \n",
       "4      bernanke     1  governor     0.0  Greenspan   0.021918 2002-08-13  \n",
       "...         ...   ...       ...     ...        ...        ...        ...  \n",
       "79933    yellen     1  governor     1.0     Yellen  16.161644 2018-01-31  \n",
       "79934    yellen     1  governor     1.0     Yellen  16.161644 2018-01-31  \n",
       "79935    yellen     1  governor     1.0     Yellen  16.161644 2018-01-31  \n",
       "79936    yellen     1  governor     1.0     Yellen  16.161644 2018-01-31  \n",
       "79937    yellen     1  governor     1.0     Yellen  16.161644 2018-01-31  \n",
       "\n",
       "[79938 rows x 22 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfdff = fdff.groupby(['date_x', 'section', 'lname'])[['svect', 'voter', 'sent']].agg({'svect': 'sum', 'voter': 'max', 'sent': 'count'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(ins):\n",
    "    print(ins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_group_std(x):\n",
    "    stdarr = np.std(np.stack(x), axis = 0)\n",
    "    new = np.tile(stdarr, (len(x), 1))\n",
    "    return pd.Series(new.tolist(), index=x.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfdff['date_section_mean'] = mfdff.groupby(['date_x', 'section'])['svect'].transform('mean')\n",
    "mfdff['date_section_std'] = mfdff.groupby(['date_x', 'section'])['svect'].transform(array_group_std).map(np.nan_to_num)\n",
    "\n",
    "mfdff['norm_svect'] = ((mfdff['svect'] - mfdff['date_section_mean']) / mfdff['date_section_std']).map(np.nan_to_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfdff['use'] = mfdff['sent'] >= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfdff.to_csv('../working-csvs/mfdff.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fed-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
