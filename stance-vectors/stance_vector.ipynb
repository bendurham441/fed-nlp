{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "import setup_modules\n",
    "from lib.preprocessing import setup_enhance, ngram_enhance, process, load_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../working-csvs/fomc-sents-w-sentiment.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams, trigrams = setup_enhance('../ngrams/bigrams', '../ngrams/trigrams')\n",
    "df['enhanced'] = df['content'].map(lambda x : ngram_enhance(x, bigrams, trigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = load_stopwords('../stopwords/stopwords.txt')\n",
    "stemmer = PorterStemmer()\n",
    "df['tokens'] = df['enhanced'].map(lambda x : process(x, stemmer=stemmer, stopwords=stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model = LdaModel.load('../models/02-29/02-29lda')\n",
    "model_dict = Dictionary.load('../models/02-29/02-29dict')\n",
    "# topic_model = LdaModel.load('../models/12-10lda')\n",
    "# model_dict = Dictionary.load('../models/12-10dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tprob_vect'] = df['tokens'].map(lambda x : topic_model[model_dict.doc2bow(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topk_topics(topic_vec, k=3):\n",
    "    probs = [item[1] for item in topic_vec]\n",
    "    probs.sort(reverse=True)\n",
    "    threshold = probs[k - 1]\n",
    "    topk = [item for item in topic_vec if item[1] >= max(threshold, 0.03)]\n",
    "    rounded = [(topic, round(prob,4)) for topic, prob in topk]\n",
    "    return rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['topk'] = df['tprob_vect'].map(lambda x : topk_topics(x, k=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recent core inflation numbers have been favorable, and most of you see continued moderation in inflation resulting from mildly restrictive policy, the ending of some temporary influences, and slower increases in shelter costs.\n",
      "[(34, 0.0862)]\n",
      "Of course, we've been forecasting an acceleration of inflation for a while and core inflation has continued to edge down.\n",
      "[(34, 0.036)]\n",
      "Assuming the earned income tax credit is already phased out, families of four earning between $20,000 and $50,000 would have marginal tax rates of around 49 percent.\n",
      "[(22, 0.0594), (37, 0.0363), (41, 0.031)]\n",
      "Our manufacturing index popped up to 22 in March after a long stretch of neutral readings.\n",
      "[(21, 0.0344), (37, 0.0315)]\n",
      "As always, it's very difficult to add intelligent new and insightful ideas after all of you have already spoken, but let me just say a couple things.\n",
      "[(18, 0.0436)]\n",
      "He noted that a lot of the volume is driven by sales over the Internet and by phone sales for holiday season packages.\n",
      "[(17, 0.1), (38, 0.031)]\n",
      "And to the downside: protectionist trade policies, restrictionist immigration policies.\n",
      "[(10, 0.0562)]\n",
      "President Minehan.\n",
      "[(37, 0.041)]\n",
      "Finally, while I still think a 50 basis point move is the better move, in this case a quarter of a loaf is better than none.\n",
      "[(2, 0.0566), (44, 0.0301)]\n",
      "As I said yesterday, the balance of evidence suggests to me that our asset purchases initiated last November contributed to the rise in inflation, but had little or no effect on real growth.\n",
      "[(23, 0.0409), (34, 0.0309)]\n",
      "Moreover, reports have been increasing of related layoffs at District suppliers of auto parts such as engines, transmissions, brake systems, exhaust systems, and electrical systems.\n",
      "[(1, 0.0404), (5, 0.0485), (35, 0.0429)]\n",
      "In support of this increased activity, the external financing cost of capital has been relatively low.\n",
      "[(22, 0.0328)]\n",
      "What are the risks that we might face if we undertake this program?\n",
      "[(23, 0.0349)]\n"
     ]
    }
   ],
   "source": [
    "for i, row in df.sample(20)[['content', 'topk']].iterrows():\n",
    "    if len(row['topk']) > 0:\n",
    "        print(row['content'])\n",
    "        print(row['topk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 45\n",
    "\n",
    "def partial_stance_vect(topics, sent_label):\n",
    "    # maybe normalize\n",
    "    total = sum([topic[1] for topic in topics])\n",
    "    svect = [0] * k\n",
    "    for topic, weight in topics:\n",
    "        svect[topic] = float(sent_label) * float(weight) / total\n",
    "    \n",
    "    return np.array(svect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sent_prob = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = df[(df['topk'].map(len) > 0) & (df['sent_prob'] > 0.5) & (df['sent'] != 0)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['svect'] = dff.apply(lambda x : partial_stance_vect(x['topk'], x['sent']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lname</th>\n",
       "      <th>date</th>\n",
       "      <th>section</th>\n",
       "      <th>content</th>\n",
       "      <th>sent_prob</th>\n",
       "      <th>sent</th>\n",
       "      <th>enhanced</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tprob_vect</th>\n",
       "      <th>topk</th>\n",
       "      <th>svect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bernanke</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>1</td>\n",
       "      <td>As we search for the signal of an incipient re...</td>\n",
       "      <td>0.819317</td>\n",
       "      <td>-1</td>\n",
       "      <td>As we search for the signal of an incipient re...</td>\n",
       "      <td>[search, signal, incipi, recoveri, heavi, nois...</td>\n",
       "      <td>[(0, 0.020856535), (1, 0.021945685), (2, 0.020...</td>\n",
       "      <td>[(36, 0.0359)]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bernanke</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>1</td>\n",
       "      <td>The direct effects of the stock market are bei...</td>\n",
       "      <td>0.654100</td>\n",
       "      <td>-1</td>\n",
       "      <td>The direct effects of the stock market are bei...</td>\n",
       "      <td>[direct, effect, stock, market, partli, offset...</td>\n",
       "      <td>[(0, 0.023129959), (1, 0.02173418), (2, 0.0206...</td>\n",
       "      <td>[(34, 0.0308)]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bernanke</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>1</td>\n",
       "      <td>Second, regarding the other source of noise, t...</td>\n",
       "      <td>0.840512</td>\n",
       "      <td>-1</td>\n",
       "      <td>Second, regarding the other source of noise, t...</td>\n",
       "      <td>[sourc, nois, data, revis, longer, blame, shal...</td>\n",
       "      <td>[(0, 0.019851433), (1, 0.020303724), (2, 0.020...</td>\n",
       "      <td>[(13, 0.0327), (18, 0.0312)]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bernanke</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>1</td>\n",
       "      <td>In particular, the revision has largely left i...</td>\n",
       "      <td>0.827082</td>\n",
       "      <td>1</td>\n",
       "      <td>In particular, the revision has largely left i...</td>\n",
       "      <td>[revis, larg, left, intact, growth, product, s...</td>\n",
       "      <td>[(0, 0.02214655), (1, 0.030765276), (2, 0.0211...</td>\n",
       "      <td>[(1, 0.0308), (37, 0.0487), (39, 0.0395)]</td>\n",
       "      <td>[0.0, 0.2588235220458918, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bernanke</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>1</td>\n",
       "      <td>I note the comments that Governor Kohn made ab...</td>\n",
       "      <td>0.803425</td>\n",
       "      <td>-1</td>\n",
       "      <td>I note the comments that Governor Kohn made ab...</td>\n",
       "      <td>[note, comment, governor, kohn, made, financi,...</td>\n",
       "      <td>[(0, 0.019764122), (1, 0.020307602), (2, 0.020...</td>\n",
       "      <td>[(27, 0.0347), (35, 0.0491)]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6701</th>\n",
       "      <td>yellen</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>2</td>\n",
       "      <td>I have thoroughly enjoyed interacting with all...</td>\n",
       "      <td>0.763187</td>\n",
       "      <td>1</td>\n",
       "      <td>I have thoroughly enjoyed interacting with all...</td>\n",
       "      <td>[enjoy, interact, terrif, staff, incred, honor...</td>\n",
       "      <td>[(0, 0.019811908), (1, 0.022919705), (2, 0.038...</td>\n",
       "      <td>[(2, 0.039)]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6701</th>\n",
       "      <td>yellen</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>2</td>\n",
       "      <td>I have heard considerable support during the g...</td>\n",
       "      <td>0.862407</td>\n",
       "      <td>1</td>\n",
       "      <td>I have heard considerable support during the g...</td>\n",
       "      <td>[heard, consider, support, round, alt, b, writ...</td>\n",
       "      <td>[(0, 0.019650389), (1, 0.019794215), (2, 0.020...</td>\n",
       "      <td>[(4, 0.056)]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6701</th>\n",
       "      <td>yellen</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>2</td>\n",
       "      <td>I suppose, although nothing obviously is set i...</td>\n",
       "      <td>0.907364</td>\n",
       "      <td>1</td>\n",
       "      <td>I suppose, although nothing obviously is set i...</td>\n",
       "      <td>[suppos, set, stone, s, a, pretti, strong, inc...</td>\n",
       "      <td>[(0, 0.020269258), (1, 0.019947713), (2, 0.021...</td>\n",
       "      <td>[(12, 0.0306), (37, 0.0392)]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6701</th>\n",
       "      <td>yellen</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>2</td>\n",
       "      <td>The minutes, if you have listened to the discu...</td>\n",
       "      <td>0.602243</td>\n",
       "      <td>1</td>\n",
       "      <td>The minutes, if you have listened to the discu...</td>\n",
       "      <td>[minut, listen, discuss, tabl, signal, greater...</td>\n",
       "      <td>[(0, 0.019247059), (1, 0.018644728), (2, 0.033...</td>\n",
       "      <td>[(2, 0.0335), (39, 0.0591)]</td>\n",
       "      <td>[0.0, 0.0, 0.36177107061022307, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6701</th>\n",
       "      <td>yellen</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>2</td>\n",
       "      <td>I mean, there was a reason to include it in bo...</td>\n",
       "      <td>0.620773</td>\n",
       "      <td>1</td>\n",
       "      <td>I mean, there was a reason to include it in bo...</td>\n",
       "      <td>[a, reason, includ, place, case, a, big, upwar...</td>\n",
       "      <td>[(0, 0.021386785), (1, 0.020505385), (2, 0.021...</td>\n",
       "      <td>[(19, 0.0309)]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79938 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         lname        date  section  \\\n",
       "0     bernanke  2002-08-13        1   \n",
       "0     bernanke  2002-08-13        1   \n",
       "0     bernanke  2002-08-13        1   \n",
       "0     bernanke  2002-08-13        1   \n",
       "0     bernanke  2002-08-13        1   \n",
       "...        ...         ...      ...   \n",
       "6701    yellen  2018-01-31        2   \n",
       "6701    yellen  2018-01-31        2   \n",
       "6701    yellen  2018-01-31        2   \n",
       "6701    yellen  2018-01-31        2   \n",
       "6701    yellen  2018-01-31        2   \n",
       "\n",
       "                                                content  sent_prob  sent  \\\n",
       "0     As we search for the signal of an incipient re...   0.819317    -1   \n",
       "0     The direct effects of the stock market are bei...   0.654100    -1   \n",
       "0     Second, regarding the other source of noise, t...   0.840512    -1   \n",
       "0     In particular, the revision has largely left i...   0.827082     1   \n",
       "0     I note the comments that Governor Kohn made ab...   0.803425    -1   \n",
       "...                                                 ...        ...   ...   \n",
       "6701  I have thoroughly enjoyed interacting with all...   0.763187     1   \n",
       "6701  I have heard considerable support during the g...   0.862407     1   \n",
       "6701  I suppose, although nothing obviously is set i...   0.907364     1   \n",
       "6701  The minutes, if you have listened to the discu...   0.602243     1   \n",
       "6701  I mean, there was a reason to include it in bo...   0.620773     1   \n",
       "\n",
       "                                               enhanced  \\\n",
       "0     As we search for the signal of an incipient re...   \n",
       "0     The direct effects of the stock market are bei...   \n",
       "0     Second, regarding the other source of noise, t...   \n",
       "0     In particular, the revision has largely left i...   \n",
       "0     I note the comments that Governor Kohn made ab...   \n",
       "...                                                 ...   \n",
       "6701  I have thoroughly enjoyed interacting with all...   \n",
       "6701  I have heard considerable support during the g...   \n",
       "6701  I suppose, although nothing obviously is set i...   \n",
       "6701  The minutes, if you have listened to the discu...   \n",
       "6701  I mean, there was a reason to include it in bo...   \n",
       "\n",
       "                                                 tokens  \\\n",
       "0     [search, signal, incipi, recoveri, heavi, nois...   \n",
       "0     [direct, effect, stock, market, partli, offset...   \n",
       "0     [sourc, nois, data, revis, longer, blame, shal...   \n",
       "0     [revis, larg, left, intact, growth, product, s...   \n",
       "0     [note, comment, governor, kohn, made, financi,...   \n",
       "...                                                 ...   \n",
       "6701  [enjoy, interact, terrif, staff, incred, honor...   \n",
       "6701  [heard, consider, support, round, alt, b, writ...   \n",
       "6701  [suppos, set, stone, s, a, pretti, strong, inc...   \n",
       "6701  [minut, listen, discuss, tabl, signal, greater...   \n",
       "6701  [a, reason, includ, place, case, a, big, upwar...   \n",
       "\n",
       "                                             tprob_vect  \\\n",
       "0     [(0, 0.020856535), (1, 0.021945685), (2, 0.020...   \n",
       "0     [(0, 0.023129959), (1, 0.02173418), (2, 0.0206...   \n",
       "0     [(0, 0.019851433), (1, 0.020303724), (2, 0.020...   \n",
       "0     [(0, 0.02214655), (1, 0.030765276), (2, 0.0211...   \n",
       "0     [(0, 0.019764122), (1, 0.020307602), (2, 0.020...   \n",
       "...                                                 ...   \n",
       "6701  [(0, 0.019811908), (1, 0.022919705), (2, 0.038...   \n",
       "6701  [(0, 0.019650389), (1, 0.019794215), (2, 0.020...   \n",
       "6701  [(0, 0.020269258), (1, 0.019947713), (2, 0.021...   \n",
       "6701  [(0, 0.019247059), (1, 0.018644728), (2, 0.033...   \n",
       "6701  [(0, 0.021386785), (1, 0.020505385), (2, 0.021...   \n",
       "\n",
       "                                           topk  \\\n",
       "0                                [(36, 0.0359)]   \n",
       "0                                [(34, 0.0308)]   \n",
       "0                  [(13, 0.0327), (18, 0.0312)]   \n",
       "0     [(1, 0.0308), (37, 0.0487), (39, 0.0395)]   \n",
       "0                  [(27, 0.0347), (35, 0.0491)]   \n",
       "...                                         ...   \n",
       "6701                               [(2, 0.039)]   \n",
       "6701                               [(4, 0.056)]   \n",
       "6701               [(12, 0.0306), (37, 0.0392)]   \n",
       "6701                [(2, 0.0335), (39, 0.0591)]   \n",
       "6701                             [(19, 0.0309)]   \n",
       "\n",
       "                                                  svect  \n",
       "0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "0     [0.0, 0.2588235220458918, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "...                                                 ...  \n",
       "6701  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "6701  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "6701  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "6701  [0.0, 0.0, 0.36177107061022307, 0.0, 0.0, 0.0,...  \n",
       "6701  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "\n",
       "[79938 rows x 11 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fomc = pd.read_csv('../working-csvs/fomc.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fomc['date_pd'] = pd.to_datetime(fomc['date'])\n",
    "fomc['year'] = fomc['date_pd'].dt.year\n",
    "fomc['month'] = fomc['date_pd'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['date_pd'] = pd.to_datetime(dff['date'].map(str))\n",
    "dff['year'] = dff['date_pd'].dt.year\n",
    "dff['month'] = dff['date_pd'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdff = dff.merge(fomc, how='left', left_on=['year', 'month', 'lname'], right_on=['year', 'month', 'member'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lname</th>\n",
       "      <th>date_x</th>\n",
       "      <th>section</th>\n",
       "      <th>content</th>\n",
       "      <th>sent_prob</th>\n",
       "      <th>sent</th>\n",
       "      <th>enhanced</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tprob_vect</th>\n",
       "      <th>topk</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>date_y</th>\n",
       "      <th>member</th>\n",
       "      <th>voter</th>\n",
       "      <th>region</th>\n",
       "      <th>female</th>\n",
       "      <th>chair</th>\n",
       "      <th>exp</th>\n",
       "      <th>date_pd_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bernanke</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>1</td>\n",
       "      <td>As we search for the signal of an incipient re...</td>\n",
       "      <td>0.819317</td>\n",
       "      <td>-1</td>\n",
       "      <td>As we search for the signal of an incipient re...</td>\n",
       "      <td>[search, signal, incipi, recoveri, heavi, nois...</td>\n",
       "      <td>[(0, 0.020856535), (1, 0.021945685), (2, 0.020...</td>\n",
       "      <td>[(36, 0.0359)]</td>\n",
       "      <td>...</td>\n",
       "      <td>2002</td>\n",
       "      <td>8</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>bernanke</td>\n",
       "      <td>1</td>\n",
       "      <td>governor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Greenspan</td>\n",
       "      <td>0.021918</td>\n",
       "      <td>2002-08-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bernanke</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>1</td>\n",
       "      <td>The direct effects of the stock market are bei...</td>\n",
       "      <td>0.654100</td>\n",
       "      <td>-1</td>\n",
       "      <td>The direct effects of the stock market are bei...</td>\n",
       "      <td>[direct, effect, stock, market, partli, offset...</td>\n",
       "      <td>[(0, 0.023129959), (1, 0.02173418), (2, 0.0206...</td>\n",
       "      <td>[(34, 0.0308)]</td>\n",
       "      <td>...</td>\n",
       "      <td>2002</td>\n",
       "      <td>8</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>bernanke</td>\n",
       "      <td>1</td>\n",
       "      <td>governor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Greenspan</td>\n",
       "      <td>0.021918</td>\n",
       "      <td>2002-08-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bernanke</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>1</td>\n",
       "      <td>Second, regarding the other source of noise, t...</td>\n",
       "      <td>0.840512</td>\n",
       "      <td>-1</td>\n",
       "      <td>Second, regarding the other source of noise, t...</td>\n",
       "      <td>[sourc, nois, data, revis, longer, blame, shal...</td>\n",
       "      <td>[(0, 0.019851433), (1, 0.020303724), (2, 0.020...</td>\n",
       "      <td>[(13, 0.0327), (18, 0.0312)]</td>\n",
       "      <td>...</td>\n",
       "      <td>2002</td>\n",
       "      <td>8</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>bernanke</td>\n",
       "      <td>1</td>\n",
       "      <td>governor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Greenspan</td>\n",
       "      <td>0.021918</td>\n",
       "      <td>2002-08-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bernanke</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>1</td>\n",
       "      <td>In particular, the revision has largely left i...</td>\n",
       "      <td>0.827082</td>\n",
       "      <td>1</td>\n",
       "      <td>In particular, the revision has largely left i...</td>\n",
       "      <td>[revis, larg, left, intact, growth, product, s...</td>\n",
       "      <td>[(0, 0.02214655), (1, 0.030765276), (2, 0.0211...</td>\n",
       "      <td>[(1, 0.0308), (37, 0.0487), (39, 0.0395)]</td>\n",
       "      <td>...</td>\n",
       "      <td>2002</td>\n",
       "      <td>8</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>bernanke</td>\n",
       "      <td>1</td>\n",
       "      <td>governor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Greenspan</td>\n",
       "      <td>0.021918</td>\n",
       "      <td>2002-08-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bernanke</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>1</td>\n",
       "      <td>I note the comments that Governor Kohn made ab...</td>\n",
       "      <td>0.803425</td>\n",
       "      <td>-1</td>\n",
       "      <td>I note the comments that Governor Kohn made ab...</td>\n",
       "      <td>[note, comment, governor, kohn, made, financi,...</td>\n",
       "      <td>[(0, 0.019764122), (1, 0.020307602), (2, 0.020...</td>\n",
       "      <td>[(27, 0.0347), (35, 0.0491)]</td>\n",
       "      <td>...</td>\n",
       "      <td>2002</td>\n",
       "      <td>8</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>bernanke</td>\n",
       "      <td>1</td>\n",
       "      <td>governor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Greenspan</td>\n",
       "      <td>0.021918</td>\n",
       "      <td>2002-08-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79933</th>\n",
       "      <td>yellen</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>2</td>\n",
       "      <td>I have thoroughly enjoyed interacting with all...</td>\n",
       "      <td>0.763187</td>\n",
       "      <td>1</td>\n",
       "      <td>I have thoroughly enjoyed interacting with all...</td>\n",
       "      <td>[enjoy, interact, terrif, staff, incred, honor...</td>\n",
       "      <td>[(0, 0.019811908), (1, 0.022919705), (2, 0.038...</td>\n",
       "      <td>[(2, 0.039)]</td>\n",
       "      <td>...</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>yellen</td>\n",
       "      <td>1</td>\n",
       "      <td>governor</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yellen</td>\n",
       "      <td>16.161644</td>\n",
       "      <td>2018-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79934</th>\n",
       "      <td>yellen</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>2</td>\n",
       "      <td>I have heard considerable support during the g...</td>\n",
       "      <td>0.862407</td>\n",
       "      <td>1</td>\n",
       "      <td>I have heard considerable support during the g...</td>\n",
       "      <td>[heard, consider, support, round, alt, b, writ...</td>\n",
       "      <td>[(0, 0.019650389), (1, 0.019794215), (2, 0.020...</td>\n",
       "      <td>[(4, 0.056)]</td>\n",
       "      <td>...</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>yellen</td>\n",
       "      <td>1</td>\n",
       "      <td>governor</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yellen</td>\n",
       "      <td>16.161644</td>\n",
       "      <td>2018-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79935</th>\n",
       "      <td>yellen</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>2</td>\n",
       "      <td>I suppose, although nothing obviously is set i...</td>\n",
       "      <td>0.907364</td>\n",
       "      <td>1</td>\n",
       "      <td>I suppose, although nothing obviously is set i...</td>\n",
       "      <td>[suppos, set, stone, s, a, pretti, strong, inc...</td>\n",
       "      <td>[(0, 0.020269258), (1, 0.019947713), (2, 0.021...</td>\n",
       "      <td>[(12, 0.0306), (37, 0.0392)]</td>\n",
       "      <td>...</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>yellen</td>\n",
       "      <td>1</td>\n",
       "      <td>governor</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yellen</td>\n",
       "      <td>16.161644</td>\n",
       "      <td>2018-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79936</th>\n",
       "      <td>yellen</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>2</td>\n",
       "      <td>The minutes, if you have listened to the discu...</td>\n",
       "      <td>0.602243</td>\n",
       "      <td>1</td>\n",
       "      <td>The minutes, if you have listened to the discu...</td>\n",
       "      <td>[minut, listen, discuss, tabl, signal, greater...</td>\n",
       "      <td>[(0, 0.019247059), (1, 0.018644728), (2, 0.033...</td>\n",
       "      <td>[(2, 0.0335), (39, 0.0591)]</td>\n",
       "      <td>...</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>yellen</td>\n",
       "      <td>1</td>\n",
       "      <td>governor</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yellen</td>\n",
       "      <td>16.161644</td>\n",
       "      <td>2018-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79937</th>\n",
       "      <td>yellen</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>2</td>\n",
       "      <td>I mean, there was a reason to include it in bo...</td>\n",
       "      <td>0.620773</td>\n",
       "      <td>1</td>\n",
       "      <td>I mean, there was a reason to include it in bo...</td>\n",
       "      <td>[a, reason, includ, place, case, a, big, upwar...</td>\n",
       "      <td>[(0, 0.021386785), (1, 0.020505385), (2, 0.021...</td>\n",
       "      <td>[(19, 0.0309)]</td>\n",
       "      <td>...</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>yellen</td>\n",
       "      <td>1</td>\n",
       "      <td>governor</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yellen</td>\n",
       "      <td>16.161644</td>\n",
       "      <td>2018-01-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79938 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          lname      date_x  section  \\\n",
       "0      bernanke  2002-08-13        1   \n",
       "1      bernanke  2002-08-13        1   \n",
       "2      bernanke  2002-08-13        1   \n",
       "3      bernanke  2002-08-13        1   \n",
       "4      bernanke  2002-08-13        1   \n",
       "...         ...         ...      ...   \n",
       "79933    yellen  2018-01-31        2   \n",
       "79934    yellen  2018-01-31        2   \n",
       "79935    yellen  2018-01-31        2   \n",
       "79936    yellen  2018-01-31        2   \n",
       "79937    yellen  2018-01-31        2   \n",
       "\n",
       "                                                 content  sent_prob  sent  \\\n",
       "0      As we search for the signal of an incipient re...   0.819317    -1   \n",
       "1      The direct effects of the stock market are bei...   0.654100    -1   \n",
       "2      Second, regarding the other source of noise, t...   0.840512    -1   \n",
       "3      In particular, the revision has largely left i...   0.827082     1   \n",
       "4      I note the comments that Governor Kohn made ab...   0.803425    -1   \n",
       "...                                                  ...        ...   ...   \n",
       "79933  I have thoroughly enjoyed interacting with all...   0.763187     1   \n",
       "79934  I have heard considerable support during the g...   0.862407     1   \n",
       "79935  I suppose, although nothing obviously is set i...   0.907364     1   \n",
       "79936  The minutes, if you have listened to the discu...   0.602243     1   \n",
       "79937  I mean, there was a reason to include it in bo...   0.620773     1   \n",
       "\n",
       "                                                enhanced  \\\n",
       "0      As we search for the signal of an incipient re...   \n",
       "1      The direct effects of the stock market are bei...   \n",
       "2      Second, regarding the other source of noise, t...   \n",
       "3      In particular, the revision has largely left i...   \n",
       "4      I note the comments that Governor Kohn made ab...   \n",
       "...                                                  ...   \n",
       "79933  I have thoroughly enjoyed interacting with all...   \n",
       "79934  I have heard considerable support during the g...   \n",
       "79935  I suppose, although nothing obviously is set i...   \n",
       "79936  The minutes, if you have listened to the discu...   \n",
       "79937  I mean, there was a reason to include it in bo...   \n",
       "\n",
       "                                                  tokens  \\\n",
       "0      [search, signal, incipi, recoveri, heavi, nois...   \n",
       "1      [direct, effect, stock, market, partli, offset...   \n",
       "2      [sourc, nois, data, revis, longer, blame, shal...   \n",
       "3      [revis, larg, left, intact, growth, product, s...   \n",
       "4      [note, comment, governor, kohn, made, financi,...   \n",
       "...                                                  ...   \n",
       "79933  [enjoy, interact, terrif, staff, incred, honor...   \n",
       "79934  [heard, consider, support, round, alt, b, writ...   \n",
       "79935  [suppos, set, stone, s, a, pretti, strong, inc...   \n",
       "79936  [minut, listen, discuss, tabl, signal, greater...   \n",
       "79937  [a, reason, includ, place, case, a, big, upwar...   \n",
       "\n",
       "                                              tprob_vect  \\\n",
       "0      [(0, 0.020856535), (1, 0.021945685), (2, 0.020...   \n",
       "1      [(0, 0.023129959), (1, 0.02173418), (2, 0.0206...   \n",
       "2      [(0, 0.019851433), (1, 0.020303724), (2, 0.020...   \n",
       "3      [(0, 0.02214655), (1, 0.030765276), (2, 0.0211...   \n",
       "4      [(0, 0.019764122), (1, 0.020307602), (2, 0.020...   \n",
       "...                                                  ...   \n",
       "79933  [(0, 0.019811908), (1, 0.022919705), (2, 0.038...   \n",
       "79934  [(0, 0.019650389), (1, 0.019794215), (2, 0.020...   \n",
       "79935  [(0, 0.020269258), (1, 0.019947713), (2, 0.021...   \n",
       "79936  [(0, 0.019247059), (1, 0.018644728), (2, 0.033...   \n",
       "79937  [(0, 0.021386785), (1, 0.020505385), (2, 0.021...   \n",
       "\n",
       "                                            topk  ...  year month      date_y  \\\n",
       "0                                 [(36, 0.0359)]  ...  2002     8  2002-08-13   \n",
       "1                                 [(34, 0.0308)]  ...  2002     8  2002-08-13   \n",
       "2                   [(13, 0.0327), (18, 0.0312)]  ...  2002     8  2002-08-13   \n",
       "3      [(1, 0.0308), (37, 0.0487), (39, 0.0395)]  ...  2002     8  2002-08-13   \n",
       "4                   [(27, 0.0347), (35, 0.0491)]  ...  2002     8  2002-08-13   \n",
       "...                                          ...  ...   ...   ...         ...   \n",
       "79933                               [(2, 0.039)]  ...  2018     1  2018-01-31   \n",
       "79934                               [(4, 0.056)]  ...  2018     1  2018-01-31   \n",
       "79935               [(12, 0.0306), (37, 0.0392)]  ...  2018     1  2018-01-31   \n",
       "79936                [(2, 0.0335), (39, 0.0591)]  ...  2018     1  2018-01-31   \n",
       "79937                             [(19, 0.0309)]  ...  2018     1  2018-01-31   \n",
       "\n",
       "         member voter    region  female      chair        exp  date_pd_y  \n",
       "0      bernanke     1  governor     0.0  Greenspan   0.021918 2002-08-13  \n",
       "1      bernanke     1  governor     0.0  Greenspan   0.021918 2002-08-13  \n",
       "2      bernanke     1  governor     0.0  Greenspan   0.021918 2002-08-13  \n",
       "3      bernanke     1  governor     0.0  Greenspan   0.021918 2002-08-13  \n",
       "4      bernanke     1  governor     0.0  Greenspan   0.021918 2002-08-13  \n",
       "...         ...   ...       ...     ...        ...        ...        ...  \n",
       "79933    yellen     1  governor     1.0     Yellen  16.161644 2018-01-31  \n",
       "79934    yellen     1  governor     1.0     Yellen  16.161644 2018-01-31  \n",
       "79935    yellen     1  governor     1.0     Yellen  16.161644 2018-01-31  \n",
       "79936    yellen     1  governor     1.0     Yellen  16.161644 2018-01-31  \n",
       "79937    yellen     1  governor     1.0     Yellen  16.161644 2018-01-31  \n",
       "\n",
       "[79938 rows x 22 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfdff = fdff.groupby(['date_x', 'section', 'lname'])[['svect', 'voter', 'sent', 'region', 'female', 'chair', 'exp']].agg({'svect': 'sum', 'voter': 'max', 'sent': 'count', 'region': 'first', 'female': 'first', 'chair': 'first', 'exp':'first'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date_x', 'section', 'lname', 'svect', 'voter', 'sent', 'region',\n",
       "       'female', 'chair', 'exp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfdff.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_group_std(x):\n",
    "    stdarr = np.std(np.stack(x), axis = 0)\n",
    "    new = np.tile(stdarr, (len(x), 1))\n",
    "    return pd.Series(new.tolist(), index=x.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfdff['date_section_mean'] = mfdff.groupby(['date_x', 'section'])['svect'].transform('mean')\n",
    "mfdff['date_section_std'] = mfdff.groupby(['date_x', 'section'])['svect'].transform(array_group_std).map(np.nan_to_num)\n",
    "\n",
    "mfdff['norm_svect'] = ((mfdff['svect'] - mfdff['date_section_mean']) / mfdff['date_section_std']).map(np.nan_to_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfdff['use'] = mfdff['sent'] >= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfdff.to_csv('../working-csvs/mfdff.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fed-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
