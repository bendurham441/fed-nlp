{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "import setup_modules\n",
    "from lib.preprocessing import setup_enhance, ngram_enhance, process, load_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../working-csvs/fomc-sents-w-sentiment.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams, trigrams = setup_enhance('../ngrams/bigrams', '../ngrams/trigrams')\n",
    "df['enhanced'] = df['content'].map(lambda x : ngram_enhance(x, bigrams, trigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = load_stopwords('../stopwords/stopwords.txt')\n",
    "stemmer = PorterStemmer()\n",
    "df['tokens'] = df['enhanced'].map(lambda x : process(x, stemmer=stemmer, stopwords=stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model = LdaModel.load('../models/02-29/02-29lda')\n",
    "model_dict = Dictionary.load('../models/02-29/02-29dict')\n",
    "# topic_model = LdaModel.load('../models/12-10lda')\n",
    "# model_dict = Dictionary.load('../models/12-10dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tprob_vect'] = df['tokens'].map(lambda x : topic_model[model_dict.doc2bow(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topk_topics(topic_vec, k=3):\n",
    "    probs = [item[1] for item in topic_vec]\n",
    "    probs.sort(reverse=True)\n",
    "    threshold = probs[k - 1]\n",
    "    topk = [item for item in topic_vec if item[1] >= max(threshold, 0.03)]\n",
    "    rounded = [(topic, round(prob,4)) for topic, prob in topk]\n",
    "    return rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['topk'] = df['tprob_vect'].map(lambda x : topk_topics(x, k=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I expect the unemployment rate to continue its decline and fall below 6 percent to about 5.8 percent by the end of this year and to 5.6 percent by the end of 2015 through 2016--5.6 percent is roughly my guess of the steady-state natural rate.\n",
      "[(10, 0.0386)]\n",
      "I had been under the impression that less-developed countries like China, because they are \"energy efficiency disadvantaged,\" would be relatively more hurt by the past rise of oil prices than the United States.\n",
      "[(33, 0.0837)]\n",
      "I am fine with \"decided to,\" but put back the strike-out that begins \"to support a stronger economic recovery.\"\n",
      "[(8, 0.0303), (20, 0.0344), (27, 0.0305)]\n",
      "That seems likely for real estate commissions in particular.\n",
      "[(0, 0.0401)]\n",
      "Housing activity remains strong, and consumer spending continues to be relatively healthy.\n",
      "[(21, 0.0381)]\n",
      "For example, our energy industry contacts expect a 30 to 50 percent reduction in drilling activity and a 35 to 60 percent reduction in capital expenditures in '09.\n",
      "[(17, 0.0377), (21, 0.0418), (41, 0.0369)]\n",
      "I think it tees up your congressional testimony.\n",
      "[(38, 0.0341)]\n",
      "On the merits, I think that President Yellen stated the economic conditions better than I could, and I subscribe to her analysis.\n",
      "[(27, 0.0335)]\n",
      "I don't think we could adjust all that easily if we were to fail to move and the economy began to deteriorate and we were looking into a deep deflationary hole.\n",
      "[(14, 0.0335), (19, 0.0426), (35, 0.0335)]\n",
      "For example, average hourly earnings actually grew more slowly in the third quarter than in the second quarter.\n",
      "[(0, 0.0311), (9, 0.0313), (37, 0.0315)]\n",
      "On inflation, as I noted, the 12-month change in overall and core PCE over the period ending in July has fallen back close to 11/2 percent.\n",
      "[(30, 0.0309), (34, 0.0314)]\n",
      "Again, it may be backward-looking, as President Evans mentioned.\n",
      "[(25, 0.03)]\n"
     ]
    }
   ],
   "source": [
    "for i, row in df.sample(20)[['content', 'topk']].iterrows():\n",
    "    if len(row['topk']) > 0:\n",
    "        print(row['content'])\n",
    "        print(row['topk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 45\n",
    "\n",
    "def partial_stance_vect(topics, sent_label):\n",
    "    # maybe normalize\n",
    "    total = sum([topic[1] for topic in topics])\n",
    "    svect = [0] * k\n",
    "    for topic, weight in topics:\n",
    "        svect[topic] = float(sent_label) * float(weight) / total\n",
    "    \n",
    "    return np.array(svect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sent_prob = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = df[(df['topk'].map(len) > 0) & (df['sent_prob'] > 0.5) & (df['sent'] != 0)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['svect'] = dff.apply(lambda x : partial_stance_vect(x['topk'], x['sent']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lname</th>\n",
       "      <th>date</th>\n",
       "      <th>section</th>\n",
       "      <th>content</th>\n",
       "      <th>sent_prob</th>\n",
       "      <th>sent</th>\n",
       "      <th>enhanced</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tprob_vect</th>\n",
       "      <th>topk</th>\n",
       "      <th>date_pd</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>svect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bernanke</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>1</td>\n",
       "      <td>As we search for the signal of an incipient re...</td>\n",
       "      <td>0.819317</td>\n",
       "      <td>-1</td>\n",
       "      <td>As we search for the signal of an incipient re...</td>\n",
       "      <td>[search, signal, incipi, recoveri, heavi, nois...</td>\n",
       "      <td>[(0, 0.020856535), (1, 0.021945685), (2, 0.020...</td>\n",
       "      <td>[(36, 0.0359)]</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>2002</td>\n",
       "      <td>8</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bernanke</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>1</td>\n",
       "      <td>The direct effects of the stock market are bei...</td>\n",
       "      <td>0.654100</td>\n",
       "      <td>-1</td>\n",
       "      <td>The direct effects of the stock market are bei...</td>\n",
       "      <td>[direct, effect, stock, market, partli, offset...</td>\n",
       "      <td>[(0, 0.023129959), (1, 0.02173418), (2, 0.0206...</td>\n",
       "      <td>[(34, 0.0308)]</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>2002</td>\n",
       "      <td>8</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bernanke</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>1</td>\n",
       "      <td>Second, regarding the other source of noise, t...</td>\n",
       "      <td>0.840512</td>\n",
       "      <td>-1</td>\n",
       "      <td>Second, regarding the other source of noise, t...</td>\n",
       "      <td>[sourc, nois, data, revis, longer, blame, shal...</td>\n",
       "      <td>[(0, 0.019851433), (1, 0.020303724), (2, 0.020...</td>\n",
       "      <td>[(13, 0.0327), (18, 0.0312)]</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>2002</td>\n",
       "      <td>8</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bernanke</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>1</td>\n",
       "      <td>In particular, the revision has largely left i...</td>\n",
       "      <td>0.827082</td>\n",
       "      <td>1</td>\n",
       "      <td>In particular, the revision has largely left i...</td>\n",
       "      <td>[revis, larg, left, intact, growth, product, s...</td>\n",
       "      <td>[(0, 0.02214655), (1, 0.030765276), (2, 0.0211...</td>\n",
       "      <td>[(1, 0.0308), (37, 0.0487), (39, 0.0395)]</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>2002</td>\n",
       "      <td>8</td>\n",
       "      <td>[0.0, 0.2588235220458918, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bernanke</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>1</td>\n",
       "      <td>I note the comments that Governor Kohn made ab...</td>\n",
       "      <td>0.803425</td>\n",
       "      <td>-1</td>\n",
       "      <td>I note the comments that Governor Kohn made ab...</td>\n",
       "      <td>[note, comment, governor, kohn, made, financi,...</td>\n",
       "      <td>[(0, 0.019764122), (1, 0.020307602), (2, 0.020...</td>\n",
       "      <td>[(27, 0.0347), (35, 0.0491)]</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>2002</td>\n",
       "      <td>8</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6701</th>\n",
       "      <td>yellen</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>2</td>\n",
       "      <td>I have thoroughly enjoyed interacting with all...</td>\n",
       "      <td>0.763187</td>\n",
       "      <td>1</td>\n",
       "      <td>I have thoroughly enjoyed interacting with all...</td>\n",
       "      <td>[enjoy, interact, terrif, staff, incred, honor...</td>\n",
       "      <td>[(0, 0.019811908), (1, 0.022919705), (2, 0.038...</td>\n",
       "      <td>[(2, 0.039)]</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6701</th>\n",
       "      <td>yellen</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>2</td>\n",
       "      <td>I have heard considerable support during the g...</td>\n",
       "      <td>0.862407</td>\n",
       "      <td>1</td>\n",
       "      <td>I have heard considerable support during the g...</td>\n",
       "      <td>[heard, consider, support, round, alt, b, writ...</td>\n",
       "      <td>[(0, 0.019650389), (1, 0.019794215), (2, 0.020...</td>\n",
       "      <td>[(4, 0.056)]</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6701</th>\n",
       "      <td>yellen</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>2</td>\n",
       "      <td>I suppose, although nothing obviously is set i...</td>\n",
       "      <td>0.907364</td>\n",
       "      <td>1</td>\n",
       "      <td>I suppose, although nothing obviously is set i...</td>\n",
       "      <td>[suppos, set, stone, s, a, pretti, strong, inc...</td>\n",
       "      <td>[(0, 0.020269258), (1, 0.019947713), (2, 0.021...</td>\n",
       "      <td>[(12, 0.0306), (37, 0.0392)]</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6701</th>\n",
       "      <td>yellen</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>2</td>\n",
       "      <td>The minutes, if you have listened to the discu...</td>\n",
       "      <td>0.602243</td>\n",
       "      <td>1</td>\n",
       "      <td>The minutes, if you have listened to the discu...</td>\n",
       "      <td>[minut, listen, discuss, tabl, signal, greater...</td>\n",
       "      <td>[(0, 0.019247059), (1, 0.018644728), (2, 0.033...</td>\n",
       "      <td>[(2, 0.0335), (39, 0.0591)]</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.36177107061022307, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6701</th>\n",
       "      <td>yellen</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>2</td>\n",
       "      <td>I mean, there was a reason to include it in bo...</td>\n",
       "      <td>0.620773</td>\n",
       "      <td>1</td>\n",
       "      <td>I mean, there was a reason to include it in bo...</td>\n",
       "      <td>[a, reason, includ, place, case, a, big, upwar...</td>\n",
       "      <td>[(0, 0.021386785), (1, 0.020505385), (2, 0.021...</td>\n",
       "      <td>[(19, 0.0309)]</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79938 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         lname        date  section  \\\n",
       "0     bernanke  2002-08-13        1   \n",
       "0     bernanke  2002-08-13        1   \n",
       "0     bernanke  2002-08-13        1   \n",
       "0     bernanke  2002-08-13        1   \n",
       "0     bernanke  2002-08-13        1   \n",
       "...        ...         ...      ...   \n",
       "6701    yellen  2018-01-31        2   \n",
       "6701    yellen  2018-01-31        2   \n",
       "6701    yellen  2018-01-31        2   \n",
       "6701    yellen  2018-01-31        2   \n",
       "6701    yellen  2018-01-31        2   \n",
       "\n",
       "                                                content  sent_prob  sent  \\\n",
       "0     As we search for the signal of an incipient re...   0.819317    -1   \n",
       "0     The direct effects of the stock market are bei...   0.654100    -1   \n",
       "0     Second, regarding the other source of noise, t...   0.840512    -1   \n",
       "0     In particular, the revision has largely left i...   0.827082     1   \n",
       "0     I note the comments that Governor Kohn made ab...   0.803425    -1   \n",
       "...                                                 ...        ...   ...   \n",
       "6701  I have thoroughly enjoyed interacting with all...   0.763187     1   \n",
       "6701  I have heard considerable support during the g...   0.862407     1   \n",
       "6701  I suppose, although nothing obviously is set i...   0.907364     1   \n",
       "6701  The minutes, if you have listened to the discu...   0.602243     1   \n",
       "6701  I mean, there was a reason to include it in bo...   0.620773     1   \n",
       "\n",
       "                                               enhanced  \\\n",
       "0     As we search for the signal of an incipient re...   \n",
       "0     The direct effects of the stock market are bei...   \n",
       "0     Second, regarding the other source of noise, t...   \n",
       "0     In particular, the revision has largely left i...   \n",
       "0     I note the comments that Governor Kohn made ab...   \n",
       "...                                                 ...   \n",
       "6701  I have thoroughly enjoyed interacting with all...   \n",
       "6701  I have heard considerable support during the g...   \n",
       "6701  I suppose, although nothing obviously is set i...   \n",
       "6701  The minutes, if you have listened to the discu...   \n",
       "6701  I mean, there was a reason to include it in bo...   \n",
       "\n",
       "                                                 tokens  \\\n",
       "0     [search, signal, incipi, recoveri, heavi, nois...   \n",
       "0     [direct, effect, stock, market, partli, offset...   \n",
       "0     [sourc, nois, data, revis, longer, blame, shal...   \n",
       "0     [revis, larg, left, intact, growth, product, s...   \n",
       "0     [note, comment, governor, kohn, made, financi,...   \n",
       "...                                                 ...   \n",
       "6701  [enjoy, interact, terrif, staff, incred, honor...   \n",
       "6701  [heard, consider, support, round, alt, b, writ...   \n",
       "6701  [suppos, set, stone, s, a, pretti, strong, inc...   \n",
       "6701  [minut, listen, discuss, tabl, signal, greater...   \n",
       "6701  [a, reason, includ, place, case, a, big, upwar...   \n",
       "\n",
       "                                             tprob_vect  \\\n",
       "0     [(0, 0.020856535), (1, 0.021945685), (2, 0.020...   \n",
       "0     [(0, 0.023129959), (1, 0.02173418), (2, 0.0206...   \n",
       "0     [(0, 0.019851433), (1, 0.020303724), (2, 0.020...   \n",
       "0     [(0, 0.02214655), (1, 0.030765276), (2, 0.0211...   \n",
       "0     [(0, 0.019764122), (1, 0.020307602), (2, 0.020...   \n",
       "...                                                 ...   \n",
       "6701  [(0, 0.019811908), (1, 0.022919705), (2, 0.038...   \n",
       "6701  [(0, 0.019650389), (1, 0.019794215), (2, 0.020...   \n",
       "6701  [(0, 0.020269258), (1, 0.019947713), (2, 0.021...   \n",
       "6701  [(0, 0.019247059), (1, 0.018644728), (2, 0.033...   \n",
       "6701  [(0, 0.021386785), (1, 0.020505385), (2, 0.021...   \n",
       "\n",
       "                                           topk    date_pd  year  month  \\\n",
       "0                                [(36, 0.0359)] 2002-08-13  2002      8   \n",
       "0                                [(34, 0.0308)] 2002-08-13  2002      8   \n",
       "0                  [(13, 0.0327), (18, 0.0312)] 2002-08-13  2002      8   \n",
       "0     [(1, 0.0308), (37, 0.0487), (39, 0.0395)] 2002-08-13  2002      8   \n",
       "0                  [(27, 0.0347), (35, 0.0491)] 2002-08-13  2002      8   \n",
       "...                                         ...        ...   ...    ...   \n",
       "6701                               [(2, 0.039)] 2018-01-31  2018      1   \n",
       "6701                               [(4, 0.056)] 2018-01-31  2018      1   \n",
       "6701               [(12, 0.0306), (37, 0.0392)] 2018-01-31  2018      1   \n",
       "6701                [(2, 0.0335), (39, 0.0591)] 2018-01-31  2018      1   \n",
       "6701                             [(19, 0.0309)] 2018-01-31  2018      1   \n",
       "\n",
       "                                                  svect  \n",
       "0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "0     [0.0, 0.2588235220458918, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "...                                                 ...  \n",
       "6701  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "6701  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "6701  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "6701  [0.0, 0.0, 0.36177107061022307, 0.0, 0.0, 0.0,...  \n",
       "6701  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "\n",
       "[79938 rows x 14 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "fomc = pd.read_csv('../working-csvs/fomc.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "fomc['date_pd'] = pd.to_datetime(fomc['date'])\n",
    "fomc['year'] = fomc['date_pd'].dt.year\n",
    "fomc['month'] = fomc['date_pd'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['date_pd'] = pd.to_datetime(dff['date'].map(str))\n",
    "dff['year'] = dff['date_pd'].dt.year\n",
    "dff['month'] = dff['date_pd'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdff = dff.merge(fomc, how='left', left_on=['year', 'month', 'lname'], right_on=['year', 'month', 'member'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lname</th>\n",
       "      <th>date_x</th>\n",
       "      <th>section</th>\n",
       "      <th>content</th>\n",
       "      <th>sent_prob</th>\n",
       "      <th>sent</th>\n",
       "      <th>enhanced</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tprob_vect</th>\n",
       "      <th>topk</th>\n",
       "      <th>...</th>\n",
       "      <th>month</th>\n",
       "      <th>svect</th>\n",
       "      <th>date_y</th>\n",
       "      <th>member</th>\n",
       "      <th>voter</th>\n",
       "      <th>region</th>\n",
       "      <th>female</th>\n",
       "      <th>chair</th>\n",
       "      <th>exp</th>\n",
       "      <th>date_pd_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bernanke</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>1</td>\n",
       "      <td>As we search for the signal of an incipient re...</td>\n",
       "      <td>0.819317</td>\n",
       "      <td>-1</td>\n",
       "      <td>As we search for the signal of an incipient re...</td>\n",
       "      <td>[search, signal, incipi, recoveri, heavi, nois...</td>\n",
       "      <td>[(0, 0.020856535), (1, 0.021945685), (2, 0.020...</td>\n",
       "      <td>[(36, 0.0359)]</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>bernanke</td>\n",
       "      <td>1</td>\n",
       "      <td>governor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Greenspan</td>\n",
       "      <td>0.021918</td>\n",
       "      <td>2002-08-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bernanke</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>1</td>\n",
       "      <td>The direct effects of the stock market are bei...</td>\n",
       "      <td>0.654100</td>\n",
       "      <td>-1</td>\n",
       "      <td>The direct effects of the stock market are bei...</td>\n",
       "      <td>[direct, effect, stock, market, partli, offset...</td>\n",
       "      <td>[(0, 0.023129959), (1, 0.02173418), (2, 0.0206...</td>\n",
       "      <td>[(34, 0.0308)]</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>bernanke</td>\n",
       "      <td>1</td>\n",
       "      <td>governor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Greenspan</td>\n",
       "      <td>0.021918</td>\n",
       "      <td>2002-08-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bernanke</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>1</td>\n",
       "      <td>Second, regarding the other source of noise, t...</td>\n",
       "      <td>0.840512</td>\n",
       "      <td>-1</td>\n",
       "      <td>Second, regarding the other source of noise, t...</td>\n",
       "      <td>[sourc, nois, data, revis, longer, blame, shal...</td>\n",
       "      <td>[(0, 0.019851433), (1, 0.020303724), (2, 0.020...</td>\n",
       "      <td>[(13, 0.0327), (18, 0.0312)]</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>bernanke</td>\n",
       "      <td>1</td>\n",
       "      <td>governor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Greenspan</td>\n",
       "      <td>0.021918</td>\n",
       "      <td>2002-08-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bernanke</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>1</td>\n",
       "      <td>In particular, the revision has largely left i...</td>\n",
       "      <td>0.827082</td>\n",
       "      <td>1</td>\n",
       "      <td>In particular, the revision has largely left i...</td>\n",
       "      <td>[revis, larg, left, intact, growth, product, s...</td>\n",
       "      <td>[(0, 0.02214655), (1, 0.030765276), (2, 0.0211...</td>\n",
       "      <td>[(1, 0.0308), (37, 0.0487), (39, 0.0395)]</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>[0.0, 0.2588235220458918, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>bernanke</td>\n",
       "      <td>1</td>\n",
       "      <td>governor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Greenspan</td>\n",
       "      <td>0.021918</td>\n",
       "      <td>2002-08-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bernanke</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>1</td>\n",
       "      <td>I note the comments that Governor Kohn made ab...</td>\n",
       "      <td>0.803425</td>\n",
       "      <td>-1</td>\n",
       "      <td>I note the comments that Governor Kohn made ab...</td>\n",
       "      <td>[note, comment, governor, kohn, made, financi,...</td>\n",
       "      <td>[(0, 0.019764122), (1, 0.020307602), (2, 0.020...</td>\n",
       "      <td>[(27, 0.0347), (35, 0.0491)]</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>bernanke</td>\n",
       "      <td>1</td>\n",
       "      <td>governor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Greenspan</td>\n",
       "      <td>0.021918</td>\n",
       "      <td>2002-08-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79933</th>\n",
       "      <td>yellen</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>2</td>\n",
       "      <td>I have thoroughly enjoyed interacting with all...</td>\n",
       "      <td>0.763187</td>\n",
       "      <td>1</td>\n",
       "      <td>I have thoroughly enjoyed interacting with all...</td>\n",
       "      <td>[enjoy, interact, terrif, staff, incred, honor...</td>\n",
       "      <td>[(0, 0.019811908), (1, 0.022919705), (2, 0.038...</td>\n",
       "      <td>[(2, 0.039)]</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>yellen</td>\n",
       "      <td>1</td>\n",
       "      <td>governor</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yellen</td>\n",
       "      <td>16.161644</td>\n",
       "      <td>2018-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79934</th>\n",
       "      <td>yellen</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>2</td>\n",
       "      <td>I have heard considerable support during the g...</td>\n",
       "      <td>0.862407</td>\n",
       "      <td>1</td>\n",
       "      <td>I have heard considerable support during the g...</td>\n",
       "      <td>[heard, consider, support, round, alt, b, writ...</td>\n",
       "      <td>[(0, 0.019650389), (1, 0.019794215), (2, 0.020...</td>\n",
       "      <td>[(4, 0.056)]</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>yellen</td>\n",
       "      <td>1</td>\n",
       "      <td>governor</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yellen</td>\n",
       "      <td>16.161644</td>\n",
       "      <td>2018-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79935</th>\n",
       "      <td>yellen</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>2</td>\n",
       "      <td>I suppose, although nothing obviously is set i...</td>\n",
       "      <td>0.907364</td>\n",
       "      <td>1</td>\n",
       "      <td>I suppose, although nothing obviously is set i...</td>\n",
       "      <td>[suppos, set, stone, s, a, pretti, strong, inc...</td>\n",
       "      <td>[(0, 0.020269258), (1, 0.019947713), (2, 0.021...</td>\n",
       "      <td>[(12, 0.0306), (37, 0.0392)]</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>yellen</td>\n",
       "      <td>1</td>\n",
       "      <td>governor</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yellen</td>\n",
       "      <td>16.161644</td>\n",
       "      <td>2018-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79936</th>\n",
       "      <td>yellen</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>2</td>\n",
       "      <td>The minutes, if you have listened to the discu...</td>\n",
       "      <td>0.602243</td>\n",
       "      <td>1</td>\n",
       "      <td>The minutes, if you have listened to the discu...</td>\n",
       "      <td>[minut, listen, discuss, tabl, signal, greater...</td>\n",
       "      <td>[(0, 0.019247059), (1, 0.018644728), (2, 0.033...</td>\n",
       "      <td>[(2, 0.0335), (39, 0.0591)]</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.36177107061022307, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>yellen</td>\n",
       "      <td>1</td>\n",
       "      <td>governor</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yellen</td>\n",
       "      <td>16.161644</td>\n",
       "      <td>2018-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79937</th>\n",
       "      <td>yellen</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>2</td>\n",
       "      <td>I mean, there was a reason to include it in bo...</td>\n",
       "      <td>0.620773</td>\n",
       "      <td>1</td>\n",
       "      <td>I mean, there was a reason to include it in bo...</td>\n",
       "      <td>[a, reason, includ, place, case, a, big, upwar...</td>\n",
       "      <td>[(0, 0.021386785), (1, 0.020505385), (2, 0.021...</td>\n",
       "      <td>[(19, 0.0309)]</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>yellen</td>\n",
       "      <td>1</td>\n",
       "      <td>governor</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yellen</td>\n",
       "      <td>16.161644</td>\n",
       "      <td>2018-01-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79938 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          lname      date_x  section  \\\n",
       "0      bernanke  2002-08-13        1   \n",
       "1      bernanke  2002-08-13        1   \n",
       "2      bernanke  2002-08-13        1   \n",
       "3      bernanke  2002-08-13        1   \n",
       "4      bernanke  2002-08-13        1   \n",
       "...         ...         ...      ...   \n",
       "79933    yellen  2018-01-31        2   \n",
       "79934    yellen  2018-01-31        2   \n",
       "79935    yellen  2018-01-31        2   \n",
       "79936    yellen  2018-01-31        2   \n",
       "79937    yellen  2018-01-31        2   \n",
       "\n",
       "                                                 content  sent_prob  sent  \\\n",
       "0      As we search for the signal of an incipient re...   0.819317    -1   \n",
       "1      The direct effects of the stock market are bei...   0.654100    -1   \n",
       "2      Second, regarding the other source of noise, t...   0.840512    -1   \n",
       "3      In particular, the revision has largely left i...   0.827082     1   \n",
       "4      I note the comments that Governor Kohn made ab...   0.803425    -1   \n",
       "...                                                  ...        ...   ...   \n",
       "79933  I have thoroughly enjoyed interacting with all...   0.763187     1   \n",
       "79934  I have heard considerable support during the g...   0.862407     1   \n",
       "79935  I suppose, although nothing obviously is set i...   0.907364     1   \n",
       "79936  The minutes, if you have listened to the discu...   0.602243     1   \n",
       "79937  I mean, there was a reason to include it in bo...   0.620773     1   \n",
       "\n",
       "                                                enhanced  \\\n",
       "0      As we search for the signal of an incipient re...   \n",
       "1      The direct effects of the stock market are bei...   \n",
       "2      Second, regarding the other source of noise, t...   \n",
       "3      In particular, the revision has largely left i...   \n",
       "4      I note the comments that Governor Kohn made ab...   \n",
       "...                                                  ...   \n",
       "79933  I have thoroughly enjoyed interacting with all...   \n",
       "79934  I have heard considerable support during the g...   \n",
       "79935  I suppose, although nothing obviously is set i...   \n",
       "79936  The minutes, if you have listened to the discu...   \n",
       "79937  I mean, there was a reason to include it in bo...   \n",
       "\n",
       "                                                  tokens  \\\n",
       "0      [search, signal, incipi, recoveri, heavi, nois...   \n",
       "1      [direct, effect, stock, market, partli, offset...   \n",
       "2      [sourc, nois, data, revis, longer, blame, shal...   \n",
       "3      [revis, larg, left, intact, growth, product, s...   \n",
       "4      [note, comment, governor, kohn, made, financi,...   \n",
       "...                                                  ...   \n",
       "79933  [enjoy, interact, terrif, staff, incred, honor...   \n",
       "79934  [heard, consider, support, round, alt, b, writ...   \n",
       "79935  [suppos, set, stone, s, a, pretti, strong, inc...   \n",
       "79936  [minut, listen, discuss, tabl, signal, greater...   \n",
       "79937  [a, reason, includ, place, case, a, big, upwar...   \n",
       "\n",
       "                                              tprob_vect  \\\n",
       "0      [(0, 0.020856535), (1, 0.021945685), (2, 0.020...   \n",
       "1      [(0, 0.023129959), (1, 0.02173418), (2, 0.0206...   \n",
       "2      [(0, 0.019851433), (1, 0.020303724), (2, 0.020...   \n",
       "3      [(0, 0.02214655), (1, 0.030765276), (2, 0.0211...   \n",
       "4      [(0, 0.019764122), (1, 0.020307602), (2, 0.020...   \n",
       "...                                                  ...   \n",
       "79933  [(0, 0.019811908), (1, 0.022919705), (2, 0.038...   \n",
       "79934  [(0, 0.019650389), (1, 0.019794215), (2, 0.020...   \n",
       "79935  [(0, 0.020269258), (1, 0.019947713), (2, 0.021...   \n",
       "79936  [(0, 0.019247059), (1, 0.018644728), (2, 0.033...   \n",
       "79937  [(0, 0.021386785), (1, 0.020505385), (2, 0.021...   \n",
       "\n",
       "                                            topk  ... month  \\\n",
       "0                                 [(36, 0.0359)]  ...     8   \n",
       "1                                 [(34, 0.0308)]  ...     8   \n",
       "2                   [(13, 0.0327), (18, 0.0312)]  ...     8   \n",
       "3      [(1, 0.0308), (37, 0.0487), (39, 0.0395)]  ...     8   \n",
       "4                   [(27, 0.0347), (35, 0.0491)]  ...     8   \n",
       "...                                          ...  ...   ...   \n",
       "79933                               [(2, 0.039)]  ...     1   \n",
       "79934                               [(4, 0.056)]  ...     1   \n",
       "79935               [(12, 0.0306), (37, 0.0392)]  ...     1   \n",
       "79936                [(2, 0.0335), (39, 0.0591)]  ...     1   \n",
       "79937                             [(19, 0.0309)]  ...     1   \n",
       "\n",
       "                                                   svect      date_y  \\\n",
       "0      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  2002-08-13   \n",
       "1      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  2002-08-13   \n",
       "2      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  2002-08-13   \n",
       "3      [0.0, 0.2588235220458918, 0.0, 0.0, 0.0, 0.0, ...  2002-08-13   \n",
       "4      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  2002-08-13   \n",
       "...                                                  ...         ...   \n",
       "79933  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  2018-01-31   \n",
       "79934  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...  2018-01-31   \n",
       "79935  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  2018-01-31   \n",
       "79936  [0.0, 0.0, 0.36177107061022307, 0.0, 0.0, 0.0,...  2018-01-31   \n",
       "79937  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  2018-01-31   \n",
       "\n",
       "         member voter    region  female      chair        exp  date_pd_y  \n",
       "0      bernanke     1  governor     0.0  Greenspan   0.021918 2002-08-13  \n",
       "1      bernanke     1  governor     0.0  Greenspan   0.021918 2002-08-13  \n",
       "2      bernanke     1  governor     0.0  Greenspan   0.021918 2002-08-13  \n",
       "3      bernanke     1  governor     0.0  Greenspan   0.021918 2002-08-13  \n",
       "4      bernanke     1  governor     0.0  Greenspan   0.021918 2002-08-13  \n",
       "...         ...   ...       ...     ...        ...        ...        ...  \n",
       "79933    yellen     1  governor     1.0     Yellen  16.161644 2018-01-31  \n",
       "79934    yellen     1  governor     1.0     Yellen  16.161644 2018-01-31  \n",
       "79935    yellen     1  governor     1.0     Yellen  16.161644 2018-01-31  \n",
       "79936    yellen     1  governor     1.0     Yellen  16.161644 2018-01-31  \n",
       "79937    yellen     1  governor     1.0     Yellen  16.161644 2018-01-31  \n",
       "\n",
       "[79938 rows x 22 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfdff = fdff.groupby(['date_x', 'section', 'lname'])[['svect', 'voter', 'sent']].agg({'svect': 'sum', 'voter': 'max', 'sent': 'count'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfdff.to_csv('../working-csvs/mfdff.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fed-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
