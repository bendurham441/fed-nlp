{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Terminology N-Gram Identification\n",
    "\n",
    "The basic idea here is to find groups of two or three words (bigrams or trigrams) which together represent some technology. As such it would be ideal to treat these groups of terms as one single token in other NLP operations. A few examples might include \"inflation expectations\" or \"unemployment rate.\" I plan on adding these ngrams to the documents.\n",
    "\n",
    "I learned about this idea from Hansen, McMahon, and Prat's 2020 paper \"Transparency and Deliberation within the FOMC: a Computational Linguistics Approach.\" These authors in turn cite Justeson and Kat'z 1995 paper \"Technical terminology: some linguistic properties and an algorithm for identification in text.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from nltk import word_tokenize, pos_tag, bigrams, trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = pd.read_csv('transcripts/speeches.csv')\n",
    "tdf = pd.read_csv('transcripts/transcripts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf['tokens'] = sdf['text'].apply(lambda x : word_tokenize(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf['tokens'] = tdf['content'].apply(lambda x : word_tokenize(str(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Important Observation*: Part of speech tags are sensitive to capitalization. I previously tried to get all bigrams, lowercase them, and then get the parts of speech, but the POS tagger tags \"I\" as a personal pronoun as expected, but tags \"i\" as a noun which is captured by the colocations used here. To combat this, I modofied my code to only lowercase trigrams and store them in a dictionary after recognizing that they fit the POS forms common to terminology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_bigram_by_pos(bigram):\n",
    "    tokens = word_tokenize(bigram)\n",
    "    pos_tags = [tag for word, tag in pos_tag(tokens)]\n",
    "    if pos_tags[0][0:2] == 'JJ' and pos_tags[1][0:2] == 'NN':\n",
    "        return True\n",
    "    elif pos_tags[0][0:2] == 'NN'and pos_tags[1][0:2] == 'NN':\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_terminology_bigrams(documents):\n",
    "    bigram_dict = {}\n",
    "    ignore_list = set()\n",
    "    for doc in documents:\n",
    "        bigram_list = [' '.join([a,b]) for (a,b) in bigrams(doc)]\n",
    "        for bigram in bigram_list:\n",
    "            if bigram in ignore_list or not keep_bigram_by_pos(bigram):\n",
    "                ignore_list.add(bigram)\n",
    "                continue\n",
    "            if bigram in bigram_dict:\n",
    "                bigram_dict[bigram.lower()] += 1\n",
    "            else:\n",
    "                bigram_dict[bigram.lower()] = 1\n",
    "    return bigram_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_trigram_by_pos(trigram):\n",
    "    tokens = word_tokenize(trigram)\n",
    "    pos_tags = [tag for word, tag in pos_tag(tokens)]\n",
    "    if pos_tags[0][0:2] == 'JJ' and pos_tags[1][0:2] == 'JJ' and pos_tags[2][0:2] == 'NN':\n",
    "        return True\n",
    "    elif pos_tags[0][0:2] == 'JJ' and pos_tags[1][0:2] == 'NN' and pos_tags[2][0:2] == 'NN':\n",
    "        return True\n",
    "    elif pos_tags[0][0:2] == 'NN' and pos_tags[1][0:2] == 'JJ' and pos_tags[2][0:2] == 'NN':\n",
    "        return True\n",
    "    elif pos_tags[0][0:2] == 'NN' and pos_tags[1][0:2] == 'NN' and pos_tags[2][0:2] == 'NN':\n",
    "        return True\n",
    "    elif pos_tags[0][0:2] == 'NN' and pos_tags[1][0:2] == 'IN' and pos_tags[2][0:2] == 'NN':\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_terminology_trigrams(documents):\n",
    "    trigram_dict = {}\n",
    "    ignore_list = set()\n",
    "    for doc in documents:\n",
    "        trigram_list = [' '.join([a,b,c]) for (a,b,c) in trigrams(doc)]\n",
    "        for trigram in trigram_list:\n",
    "            if trigram in ignore_list or not keep_trigram_by_pos(trigram):\n",
    "                ignore_list.add(trigram)\n",
    "                continue\n",
    "            if trigram in trigram_dict:\n",
    "                trigram_dict[trigram.lower()] += 1\n",
    "            else:\n",
    "                trigram_dict[trigram.lower()] = 1\n",
    "    return trigram_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = tdf['tokens'].tolist() + sdf['tokens'].tolist()\n",
    "bgdict = get_terminology_bigrams(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgdict = get_terminology_trigrams(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_bigrams = {bg: freq for bg,freq in bgdict.items() if freq > 100}\n",
    "relevant_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_trigrams = {tg: freq for tg,freq in tgdict.items() if freq > 50}\n",
    "relevant_trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('ngrams', 'bigrams'), 'w') as bg_file:\n",
    "    for bg in relevant_bigrams:\n",
    "        bg_file.write(bg + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('ngrams', 'trigrams'), 'w') as tg_file:\n",
    "    for tf in relevant_trigrams:\n",
    "        tg_file.write(tf + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fed-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
