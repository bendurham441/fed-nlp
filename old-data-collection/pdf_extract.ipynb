{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Extraction from Speech PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'pdfs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function extracts information from two main formats, or ignores certain files if they don't match a given format. I deal with non-matching documents later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_from_pdf(fname):\n",
    "    record = {}\n",
    "    record['filename'] = fname \n",
    "    \n",
    "    reader = PdfReader(os.path.join(folder, fname))\n",
    "    meta = reader.metadata\n",
    "    pages = reader.pages\n",
    "\n",
    "    format = 0\n",
    "        \n",
    "    # identify which format a document belongs to\n",
    "    first_page = pages[0].extract_text()\n",
    "    if first_page.find('For release on delivery') >= 0 or first_page.find('For release at') >= 0:\n",
    "        format = 1\n",
    "        pages = pages[1:]\n",
    "        first_page = first_page.replace('\\n', '')\n",
    "\n",
    "        record['date'] = re.search('\\w* [0-3]{0,1}[0-9]{1} ?, [0-9]{4}', first_page).group()\n",
    "        record['author'] = re.search('(?:[rR]emarks|Statement)?[ ]{1,2}by[ ]{1,3}([\\w]+ [\\w]. [\\w]+|[\\w]+ [\\w]+)[ ]{1,3}', first_page).groups()[0]\n",
    "\n",
    "        if '/Title' in meta.keys():\n",
    "            if ':' in meta['/Title']:\n",
    "                record['title'] = meta['/Title'].split(':')[1].strip()\n",
    "            elif ' -' in meta['/Title']:\n",
    "                record['title'] = meta['/Title'].split('-')[1].strip()\n",
    "            else:\n",
    "                record['title'] = meta['/Title']\n",
    "        else:\n",
    "            record['title'] = None\n",
    "    elif 'Creator' in meta.keys() and 'PScript5' in meta['/Creator']:\n",
    "        # Skip documents of this format, which have to be manually extracted\n",
    "        format = 2\n",
    "        record['title'] = None\n",
    "        record['date'] = None\n",
    "    else:\n",
    "        # The remaining examples fit into the following format\n",
    "        split_title = meta['/Title'].split(':')\n",
    "        record['author'] = split_title[0]\n",
    "        record['date'] = re.search('[0-3]{0,1}[0-9]{1} \\w*[,]{0,1} [0-9]{3,4}|\\w+ [0-9]{1,2},? [0-9]{4}', meta['/Subject']).group()\n",
    "        record['title'] = split_title[1].strip()\n",
    "\n",
    "    combined_text = \"\"\n",
    "    for i, page in enumerate(pages):\n",
    "        text = page.extract_text()\n",
    "        if format == 0:\n",
    "            # remove preamble, only on first page\n",
    "            if i == 0:\n",
    "                text = text.split('*')[-1]\n",
    "            text = text.strip()\n",
    "            # remove page number and footer\n",
    "            text = text[:text.rfind('\\n')]\n",
    "            # remove footnotes\n",
    "            text = text[:text.rfind('        ')]\n",
    "            text = text.replace('\\n', '')\n",
    "        elif format == 1:\n",
    "            format == 1\n",
    "            # remove page numbers\n",
    "            text = re.sub('- [0-9]{1,2} -', '', text)\n",
    "            # remove footnotes\n",
    "            text = re.sub('^[0-9]+[ ]{1}\\w.*', '', text, flags=re.M)\n",
    "            # remove footnote references\n",
    "            text = re.sub('^[1-9]+[ ].', '', text, flags=re.M)\n",
    "            # remove empty space\n",
    "            text= re.sub('\\n', '', text)\n",
    "        combined_text = (combined_text + ' ' + text).strip()\n",
    "\n",
    "    record['text'] = combined_text\n",
    "\n",
    "    return record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I identified some anamolies, which I exclude from this process and just extract information from manually given how few there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "problem = ['r220509b.pdf', 'r220615g.pdf', 'r210114b.pdf', 'r211128e.pdf', 'r161003a.pdf', 'r221128l.pdf']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then create an array of entries to form a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'pdfs'\n",
    "records = []\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    if file in problem:\n",
    "        continue\n",
    "    record = extract_data_from_pdf(file)\n",
    "    records.append(record)\n",
    "    \n",
    "records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Had to manually redownload r150416a.pdf because while it showed up in the folder, it was empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I fix a few typos that messed up date parsing, and then parse the date and save the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['author'].value_counts()\n",
    "\n",
    "df['date'].fillna('',inplace=True)\n",
    "\n",
    "df[(df['date'] == '') | (df['date'].str.contains('Mach'))]\n",
    "\n",
    "# fixing typos\n",
    "df.loc[df['date'].str.contains('Mach'), 'date'] = '15 March 2016' #mistyped date\n",
    "df.loc[df['filename'] == 'r171020g.pdf', 'date'] = '18 October 2017' #mistyped date\n",
    "df.loc[1177, 'date'] = 'June 17, 2022'\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'], format='mixed')\n",
    "\n",
    "df.to_csv('speeches.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I combine the documents that I systematically extracted information from with those that I had to manually extract information from, and then save the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "manual = pd.read_csv('manual.csv')\n",
    "df = pd.read_csv('speeches.csv', index_col=0)\n",
    "df = pd.concat([df,manual], ignore_index=True)\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "df.to_csv('all_speeches.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fed-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
